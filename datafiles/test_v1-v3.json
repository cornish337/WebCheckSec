[
  {
    "Category": "GENERAL",
    "Sub Category": "Baseline checks and enumeration",
    "Item": "Run ranger automation",
    "Description": "Perform an automated baseline scan of the application to quickly identify obvious security issues and map out the attack surface. This test verifies that common vulnerabilities and misconfigurations (e.g., default credentials, known CVEs, open directories) are checked early using automated tools. It’s important because automation can catch low-hanging fruit and provide broad coverage – things an attacker would easily find – ensuring no basic weakness is overlooked before deeper manual testing.",
    "Tools": "- **Automated Scanners**: Use tools like **OWASP ZAP (Baseline scan)** or **Nikto** to scan for common web server issues and known vulnerabilities. These tools will crawl the site and report issues like server version disclosures, directory indexing, or default files.\n- **Nuclei**: Run a set of **Nuclei** templates for known vulnerabilities/misconfigurations. Nuclei has templates for default admin pages, config leaks, CVE-specific checks, etc., which can be launched in one go to flag any low-hanging issues.\n- **Burp Suite (Automated)**: Burp’s **Active Scanner** or extensions (like Active Scan++ or task scheduler) can perform an initial probe for common vulnerabilities (SQLi, XSS, etc.) across all discovered pages. Combine this with Burp’s **Spider** to ensure all endpoints are covered.\n- These automated tasks can be orchestrated via a script or tool suite (sometimes referred to as a “ranger” automation script) to run sequentially. The results give a broad overview that guides where to do focused manual testing next. Always review findings manually to weed out false positives.",
    "Links": "- **OWASP WSTG** – *Information Gathering* and *Configuration Management Testing* sections stress running automated discovery and vulnerability scans early. They outline using scanners to map the application and catch obvious misconfigurations.\n- **NIST SP 800-115** – The NIST security testing guide advises using automated **vulnerability scanners** in the assessment’s discovery phase to quickly enumerate hosts, services, and known vulnerabilities. This ensures comprehensive coverage of common issues before manual testing.",
    "Applicability": "Applicable to virtually all web apps. Only mark N/A if the environment strictly forbids automation (e.g., a very sensitive app where scanning is not allowed) or if the scope is so limited (a simple static page) that an automated scan would be redundant. In standard engagements, running baseline automation is always recommended to uncover easy-to-find issues. Even single-page apps or APIs benefit from automation to ensure no well-known weakness is missed.",
    "Sources": "https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/01-Information_Gathering/README.html, https://nvlpubs.nist.gov/nistpubs/legacy/sp/nistspecialpublication800-115.pdf"
  },
  {
    "Category": "GENERAL",
    "Sub Category": "Baseline checks and enumeration",
    "Item": "Directory, header, file and parameter enumeration",
    "Description": "Systematically discover hidden or unreferenced content and inputs in the application. This includes enumerating directories/files (to find pages or data not linked in the UI), examining HTTP headers (for insights or security settings), and finding HTTP parameters (including ones not exposed by the UI). This matters because sensitive information or functionalities (admin pages, backup files, debug endpoints, or optional parameters) are often accessible if one knows where to look – and attackers will try to find these. By enumerating these, we ensure the app isn’t exposing anything unintended that could lead to compromise.",
    "Tools": "- **Directory/File Brute-Forcing**: Use tools like **ffuf**, **Gobuster**, or **Dirbuster** with common wordlists (e.g., SecLists) to find hidden directories and files. For example, try enumerating `/admin`, `/backup/`, `.git/`, or files like *config.php*, *backup.zip*. These tools send a high volume of requests with different filenames and analyze which ones return valid responses.\n- **Parameter Discovery**: Utilize a Burp Suite extension like **ParamMiner** to guess hidden HTTP parameters. This involves sending requests with common parameter names (like `?debug=true` or `X-Original-URL`) and seeing if the application responds differently. Burp Intruder can also test parameter fuzzing by inserting payloads in parameter names as well as values to see undisclosed functionality.\n- **HTTP Headers Inspection**: Intercept and review HTTP response headers using Burp or **OWASP ZAP**. Look for any unusual headers (e.g., `X-Debug-Info`, `X-Version`), which might reveal internal info or debugging is enabled. Also check standard security headers here (like CSP, HSTS) – their presence or absence can be noted for other tests. For request headers, you can try adding headers like `X-Forwarded-For` or `X-Originating-IP` to probe if the app trusts them (which might surface in logs or behavior).\n- **Infrastructure Enumeration**: If applicable, use tools like **Nmap** (with http-enum or http-index scripts) to enumerate well-known files and directories. This can supplement web-specific tools by discovering server config files or default pages.\n- Many of these tests can be grouped: e.g., run a dir brute-force that finds an `/api/` directory, then enumerate parameters on its endpoints. By combining results (files found, parameters found), you build a more complete attack surface map.",
    "Links": "- **OWASP WSTG** – *Content Discovery* and *File/Directory Enumeration* (WSTG-INFO-*** and WSTG-CONFIG-***): Emphasize trying common filenames, backup extensions, and unlinked pages. Also discusses reviewing server headers and responses for hidden clues.\n- **OWASP Cheat Sheet – Content Discovery**: Provides techniques and common wordlists for finding hidden files and parameters (e.g., using robots.txt clues, common admin paths).\n- **PTES (Pre-Test Phase)** – Recommends comprehensive enumeration of application entry points (URLs, parameters) as a foundation for later testing, aligning with this step of gathering all potential targets.",
    "Applicability": "Nearly always relevant. Only not applicable if the application is extremely minimal (a single static page with no inputs) – and even then, checking for server headers and any accessible files is quick. In most cases, dynamic apps, APIs, and even static file servers may have hidden paths or parameters. This should be done unless it’s absolutely certain there are no hidden elements (which is rare without testing). If the engagement scope excludes active probing or if credentials are needed to see anything (and none are provided), then broad enumeration might be limited, but generally some form of this test applies to every assessment.",
    "Sources": "https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/04-Review_Old_Backup_and_Unreferenced_Files_for_Sensitive_Information, https://owasp.org/www-community/attacks/Content_Spanning_Enumeration"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "SDLC",
    "Item": "SDLC to address security in all development stages",
    "Description": "Verify that the software development life cycle (SDLC) explicitly integrates security activities at every stage (requirements, design, coding, testing, deployment, maintenance). This means the organization has processes to consider security early (not just as an afterthought). A security-aware SDLC helps catch design flaws and vulnerabilities before the app goes live. Without it, critical issues might slip in due to lack of threat modeling, code review, or security testing during development, increasing the likelihood of vulnerabilities in the deployed application.",
    "Tools": "- **Process Review & Interviews**: This is more of a procedural check. Interview developers or project managers to confirm if there are security checkpoints (e.g., threat modeling sessions during design, code review with security in mind, use of SAST/DAST tools during coding/testing). Request any SDLC documentation or policies that outline secure coding guidelines and security requirements in user stories.\n- **Documentation Audit**: Examine artifacts like design documents or requirement backlogs for evidence of security considerations (e.g., “user password must be stored hashed with Bcrypt” in requirements). The presence of security user stories or abuse cases is a positive sign.\n- **Tool Integration**: Check if the project uses tools like **GitHub/GitLab CI security scans**, **OWASP dependency-check** for third-party libraries, or if they have a **security champion** role. The existence of these tools in the build pipeline indicates security is built-in at each stage.\n- Optionally, if the organization uses a maturity model (like **OWASP SAMM**), see if they have self-assessed or have metrics to track security activities in development. This isn’t a “tool” per se, but it’s evidence of practice.",
    "Links": "- **OWASP ASVS 1.1** – Requires that an organization establish an SDLC with security considerations (verification requirement V1.1.1). Essentially, it mandates having a security-focused methodology in development.\n- **NIST SSDF (SP 800-218)** – NIST’s Secure Software Development Framework emphasizes adding security steps in each SDLC phase (e.g., security requirements, design reviews, code analysis). It provides guidance on integrating security from planning to deployment.\n- **OWASP SAMM** – The Software Assurance Maturity Model provides a framework for assessing and improving SDLC security. It highlights practices like security requirements and secure architecture as part of a mature SDLC.",
    "Applicability": "Applies to any organized development process. If the application is acquired off-the-shelf or not developed in-house, this might be N/A (since there is no SDLC under the tester’s purview). Also, if you are only testing a deployed app and not assessing the development process, you might mark this N/A. In most assessments for custom-built apps, however, understanding if the dev lifecycle includes security (or not) is valuable information.",
    "Sources": "https://owasp.org/ASVS/Pages/Requirement_1.1_Security_Architecture#v11-understand-security-requirements, https://csrc.nist.gov/publications/detail/sp/800-218/final"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "SDLC",
    "Item": "Threat modelling is in place for all design changes or sprint planning",
    "Description": "Confirm that the team performs threat modeling during design changes or at sprint planning, meaning they systematically think about potential attackers, threats, and mitigations for new features or changes. Effective threat modeling ensures security is considered at the design phase – identifying risky components or abuse cases early. Without it, new features might introduce vulnerabilities because developers didn’t anticipate how an attacker might target them or what new trust boundaries are created.",
    "Tools": "- **Interview & Process Check**: Ask the development team how they incorporate threat modeling. Do they use frameworks like **STRIDE** or **PASTA** during design meetings? Evidence could be in design documents listing threats/mitigations or tickets in the backlog for threat model reviews.\n- **Examine Artifacts**: If threat models exist, review them. These might be data flow diagrams (DFDs) with annotations of threats, or a list of identified threats per feature and how they were addressed. The presence of these documents for each significant change or feature is a good sign.\n- **Tools for Threat Modeling**: Some teams use tools like **OWASP Threat Dragon** or Microsoft’s **Threat Modeling Tool**. Inquire if such tools are used and if outputs (threat lists) are stored. While not hands-on “tools” for a tester, seeing their output or usage is part of verifying this requirement.\n- **Sprint Ceremonies**: If possible, sit in (or get minutes from) a sprint planning meeting to see if security questions are raised for each user story (e.g., “What’s the worst that could happen if this feature is abused?”). This indicates threat modeling thinking is embedded in planning.",
    "Links": "- **OWASP ASVS 1.1** – Highlights threat modeling as a control (V1.1.2: “Verify that threat modeling is performed regularly for critical or new functionality”). ASVS requires that design changes undergo a security review, essentially what threat modeling provides.\n- **OWASP WSTG – Architecture Design**: The WSTG suggests reviewing architecture and design for security, implying threat modeling should inform the assessment of new features.\n- **Microsoft SDL** – Microsoft’s Secure Development Lifecycle mandates threat modeling during the design phase of each iteration. This is a widely recognized best practice: every new feature or change should have its threats enumerated and addressed.",
    "Applicability": "Relevant for projects using iterative development (sprints) or any process where features change over time. If an application is in maintenance with no new features and threat modeling was done once initially, ongoing threat modeling for each change might be N/A (because no new design changes). It’s also less applicable if the organization follows a waterfall model with one-time threat modeling at project start (then you’d evaluate that one-time model instead). In most modern Agile teams, this should be done each sprint, so flag it N/A only if development is basically complete or outside the scope of the review.",
    "Sources": "https://owasp.org/ASVS/Pages/Requirement_1.1_Security_Architecture#v112-threat-modeling, https://www.microsoft.com/en-us/securityengineering/sdl/practices#phase=requirementdesign"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "SDLC",
    "Item": "Verify all user stories consider security constraints (e.g. a user should be able to edit their profile but not others)",
    "Description": "Ensure that for each user story or functional requirement, the security constraints and access controls are explicitly noted. In practice, this means that acceptance criteria for features include what users *should not* be able to do, not just the positive functionality. For example, a story “User can edit their profile” should include the caveat “and not be able to edit others’ profiles.” This matters because it embeds security and access control into the development process – developers and testers will then naturally test those constraints. If security constraints aren’t documented in user stories, there’s a risk that devs might implement a feature without proper access checks or other security considerations, since it wasn’t clearly defined as part of the requirement.",
    "Tools": "- **Backlog Review**: Look at the project’s issue tracker or story backlog (e.g., in JIRA, Trello). Check a sample of user stories or requirements for explicit security-related acceptance criteria (like authorization rules, data validation rules). For instance, a story might say “As an admin, I can delete any user’s post, but regular users can only delete their own posts.” The second clause is the security constraint.\n- **Interview**: Ask product owners or developers how they capture security in requirements. Do they use misuse cases or abuse stories (like “As an attacker, I should not be able to X”)? Their approach will indicate if it’s systematic or ad-hoc.\n- **Review Test Cases**: If QA has test cases for user stories, see if negative tests are included (e.g., test that user A cannot access user B’s data). The presence of these implies the story had that constraint defined from the start.\n- There isn’t a specific automation tool for this verification; it’s more about process. However, traceability tools in ALM (Application Lifecycle Management) software can show if each story has a linked security requirement or not. Utilizing those, you could gauge coverage (e.g., how many stories have a “Security” tag or sub-task).",
    "Links": "- **OWASP ASVS 1.1.3** – Mentions that all functional requirements should include security requirements. This aligns with making sure user stories (which are bite-size requirements) document their security constraints.\n- **OWASP Proactive Controls (2018) – C1: Define Security Requirements**: Emphasizes building security into requirements phase. Each feature’s requirements should state what security controls or limits apply, which is essentially what this item is asking for.\n- **NIST SP 800-64 (Secure Software Development)** – Advises that security requirements be identified alongside functional requirements. In an Agile context, that means each user story should carry its security considerations.",
    "Applicability": "This is applicable to teams that use user stories or similar requirement definitions (common in Agile methodologies). If the development process doesn’t use user stories (maybe a formal spec or use cases instead), then the concept still applies: check those specs for security constraints. Only mark N/A if you truly have no access to requirements (black-box testing with zero insight into dev process) or if the application is COTS with no custom dev requirements. In a typical custom development project, this check is usually relevant.",
    "Sources": "https://owasp.org/www-project-proactive-controls/#div-c1, https://csrc.nist.gov/publications/detail/sp/800-64/rev2/final"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "SDLC",
    "Item": "Verify documentation and justification of trust boundaries",
    "Description": "Confirm that the system’s architecture documentation clearly identifies trust boundaries (places where the level of trust or privilege changes, such as between client and server, or between the web app and the database) and that these boundaries are justified and secure. Essentially, the design should show where data transitions from one trust context to another (e.g., from the internet into the internal network, or from an authenticated user zone to an admin zone) and explain how those boundaries are protected. This matters because unclear or undocumented trust boundaries often lead to assumptions that attackers exploit – for example, if it’s not documented that “the API gateway is a trust boundary,” developers might not validate input assuming some upstream component did. Well-defined boundaries help ensure proper controls (like authentication, encryption, validation) are in place whenever data or commands cross into a more trusted zone.",
    "Tools": "- **Architecture Diagram Review**: Obtain network and application architecture diagrams. Look for annotations or demarcations like firewalls, tiers (web, app, DB), and any external integrations. Verify that each line crossing from one component to another is recognized as a potential trust boundary. For instance, a call from the web server to the database crosses a boundary where input should be sanitized and authenticated. If diagrams aren’t annotated, that might indicate this hasn’t been documented.\n- **Threat Model Documents**: If threat modeling is done (from a previous item), those often explicitly call out trust boundaries. Check if the threat model lists boundaries and the rationale for trust decisions (e.g., “Module A and Module B run under different privileges, so their interface is a trust boundary – input is validated and authenticated here”).\n- **Interviews**: Ask architects or senior developers to describe the trust boundaries. A justified trust boundary means they can explain why, say, a separate microservice is or isn’t in the same trust domain. For example, *“We consider the client browser to server connection a trust boundary – hence we enforce TLS and input validation at that point”*.\n- No automated tool will “detect” trust boundaries; this is a design verification. However, using a checklist (like OWASP Architectural Review checklist) can ensure you ask about typical boundaries: user-to-app, app-to-database, app-to-external system, etc., and see if each is documented and has controls.",
    "Links": "- **OWASP ASVS 1.1.4** – Requires that architecture documentation includes delineation of trust boundaries. It expects that each trust boundary is identified and security controls are in place at those boundaries.\n- **OWASP WSTG – Architecture Review**: Suggests reviewing the design to identify trust zones and boundaries, ensuring controls like validation, authentication, and encryption are applied when crossing them.\n- **NIST SP 800-53 (SA-17)** – The control “Security Architecture” in NIST 800-53 asks for an architecture that includes considerations of trust (like separating different domains and documenting interactions). While more high-level, it aligns with marking and justifying trust boundaries in system docs.",
    "Applicability": "Relevant for any non-trivial application. Even simple web apps have at least one trust boundary (user vs server). This would be N/A only if no architecture documentation exists and the test scope doesn’t allow architectural analysis (pure black-box with zero design insight). In a typical architecture review or white-box pentest, you should evaluate this. If the application is extremely simple (e.g., static site with no back-end logic), trust boundaries are minimal (client vs server), but still should be noted. Otherwise, assume it applies.",
    "Sources": "https://owasp.org/ASVS/Pages/Requirement_1.1_Security_Architecture#v114-document-architecture, https://cwe.mitre.org/data/definitions/486.html"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "Authentication Architectural Requirements",
    "Item": "Verify use of low privilege OS accounts for applications",
    "Description": "Ensure that the application (and its components) run under operating system accounts with the minimum privileges necessary, rather than as a superuser or high-privileged account. This is about defense in depth: if an attacker compromises the application, using a low-privilege OS account limits the damage (the attacker can’t immediately take over the whole server or OS). Conversely, if the app runs as admin/root, any code execution or directory traversal becomes far more severe. Verifying this means checking deployment configurations and processes to see that accounts like *www-data*, *tomcat*, or custom least-privileged users are used for the app service.",
    "Tools": "- **Configuration Inspection**: If you have access to the server (during a config review phase), check the user under which the application process is running. On Linux, this might mean running `ps -ef` and seeing that the web server (e.g., Apache, Nginx, Tomcat) is running as a limited user (not root). For Windows, ensure services run as NetworkService or a dedicated low-priv user, not as LocalSystem unless absolutely necessary.\n- **File/Process Access Tests**: Even in a black-box test, you might glean some info. For example, attempt to access a protected file via the app (like read `/etc/shadow` on Linux or `C:\\Windows\\System32\\...` on Windows through a file access vulnerability). If the application user is low privilege, direct access will be denied. This is more of an indirect test by probing for common protected resources (though this blurs into vulnerability testing, not just architecture).\n- **Review Deployment Scripts or Dockerfiles**: If the app is containerized or has infrastructure as code, inspect those. Dockerfiles, for instance, should use a non-root user (`USER appuser`). Kubernetes manifests should not set privileged pods and should run as specific user IDs. Checking these configurations verifies enforcement of least privilege at runtime.\n- **Ask the DevOps/Engineers**: Sometimes the quickest way – inquire which OS user the app runs under and what privileges it has. Verify that answer by cross-checking with documentation or a quick runtime test as above.",
    "Links": "- **OWASP ASVS 1.2.1** – States that all components should run with minimal necessary privileges, referencing that applications shouldn’t run as root/admin. It’s an explicit requirement to use low-privilege accounts.\n- **OWASP Server Security Configuration Guide** – Recommends configuring web and application servers to use dedicated service accounts with restricted permissions (no shell login, limited folder access).\n- **NIST SP 800-53 (CM-6 Least Functionality)** – Although general, it implies that systems should be configured to provide only essential capabilities and restrict privileges; running services under least privilege accounts is part of that practice.",
    "Applicability": "Applies to almost all server-side applications and services. Only N/A if the application runs in an environment where OS accounts aren’t applicable (e.g., serverless functions running in a managed sandbox, where you rely on the platform’s isolation). In traditional deployments (VMs, containers, on-prem servers), this is always relevant. It might also be N/A for front-end only components (pure JavaScript in browser), but for anything hosted, check this.",
    "Sources": "https://cheatsheetseries.owasp.org/cheatsheets/Server_Security_Cheat_Sheet.html#operating-system-accounts, https://cwe.mitre.org/data/definitions/250.html"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "Authentication Architectural Requirements",
    "Item": "Verify communication between application components are authenticated",
    "Description": "Check that when different components or microservices of the application talk to each other, they do so in an authenticated manner – meaning each component verifies the identity/credentials of the others. For example, if the web front-end calls a backend API or database, does that API require a key, token, or certificate from the caller? This prevents an attacker who gains network access from impersonating a service. It’s important because as applications get split into services, trust should not be implicit; otherwise, a compromised or rogue service (or an external attacker) could call internal APIs without restriction if they aren’t verifying identities.",
    "Tools": "- **Architecture Diagram & Config Review**: Identify all the inter-component communications (web server to app server, app server to database, microservice A to B, etc.). For each, determine what authentication mechanism is in place. This could be checking API gateway configs (are services using mutual TLS with certificates? Are they passing JWTs or API keys on internal calls?). Configuration files (like cloud gateway settings or Docker/Kubernetes secrets) may reveal internal auth tokens or certificates in use.\n- **Traffic Analysis**: If you can observe internal traffic (in a test environment), use a tool like **Wireshark** or a **proxy** between services to capture communications. Verify that credentials or tokens are being used. For instance, when Service A calls Service B, do you see an Authorization header or a client certificate being presented? If internal APIs are called over plain protocols with no auth, that’s a finding.\n- **Simulated Calls**: If you have the network access in a test environment, try to directly call an internal service endpoint without credentials. For example, call an internal API URL that the front-end would call, but do it manually without the expected token. If the request succeeds or you can perform actions, that indicates missing internal authentication. (This must be done carefully and usually only in a controlled environment.)\n- **Review Documentation/Policies**: Sometimes architecture docs or security policies state that “all service-to-service calls must be mutually authenticated”. Cross-check such statements with actual implementation evidence (certs, tokens in config).",
    "Links": "- **OWASP ASVS 1.2.2** – Requires that all communications between components are authenticated (and secured). This maps exactly to ensuring microservice/API calls aren’t implicitly trusted.\n- **OWASP Microservices Security** – Guidelines suggest using mutual TLS or signed tokens (JWT/OAuth) for service-to-service auth, rather than trusting network location. This item aligns with those best practices.\n- **NIST Zero Trust Architecture (NIST SP 800-207)** – Though broad, it advocates that no network segment should be inherently trusted. Each request, even internal, should be authenticated and authorized. This underpins the need for inter-component authentication.",
    "Applicability": "Applicable to multi-tier or microservice architectures. In a monolithic app where everything runs in one process, it’s less directly relevant (though the database authentication still applies – the app should auth to the DB). Mark N/A only if the application truly has no distinct components (e.g., a simple PHP app talking to a local DB with OS file socket authentication might be considered out-of-scope for this). Otherwise, any web app with separate front-end/back-end, or using external services, should have this verified.",
    "Sources": "https://owasp.org/ASVS/Pages/Requirement_1.2_Authentication_Architectural#v122, https://csrc.nist.gov/publications/detail/sp/800-207/final"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "Authentication Architectural Requirements",
    "Item": "Verify implementation of centralised security controls",
    "Description": "Ensure the application leverages centralized security mechanisms rather than duplicating ad-hoc controls in multiple places. Examples: using a central authentication service (like LDAP/OAuth or a single sign-on provider) rather than separate login logic in each module, or a unified access control library that all components call. Centralized controls (for auth, access control, input validation, etc.) help maintain consistency and are less prone to human error. If every developer writes their own security check, some part of the app might do it incorrectly. A central, well-vetted control reduces that risk and makes updates easier (fix in one place).",
    "Tools": "- **Architecture Review**: Identify security functions like authentication, authorization, input sanitization, logging, etc., and see if the design uses centralized services/libraries for these. For instance, verify that all modules use a common auth service or API gateway for login. If different parts of the app have separate login pages or separate user stores, that’s a red flag.\n- **Code Review**: If available, scan the codebase for multiple implementations of the same thing. E.g., search for password validation logic in multiple modules – ideally, there should be one module or service responsible for that. Tools like **grep** or static analysis can find duplicates. If you find hard-coded security decisions scattered around (like various SQL queries checking roles), that might indicate no central enforcement point.\n- **Interviews**: Ask developers/architects if they use frameworks or centralized services: *“Do you use a single sign-on or centralized user identity service?”*, *“Is there a global access control mechanism (like an API gateway or middleware) that every request goes through?”*. Their answers will reveal if security is consistently applied or if it’s siloed.\n- **Testing**: It’s a bit conceptual, but consider a scenario: if you bypass one component’s security (like calling a backend API directly), would a central control still enforce rules? For example, if an API gateway is the centralized control, calling the microservice directly (bypassing the gateway) should fail. If it doesn’t, that means security checks were not centralized at the gateway and had to be done individually (and one was missed). This kind of test can show whether central controls are truly in place.",
    "Links": "- **OWASP ASVS 1.2.3** – Advises that security controls (like authentication, access control, input validation) be implemented in a centralized way. The idea is one primary location or service for each control.\n- **OWASP Top 10: A5-Security Misconfiguration** – One cause of misconfig is not having centralized config or controls, leading to inconsistent settings. Centralizing security controls helps avoid misconfiguration and omissions in some parts of the app.\n- **PTES Architectural Review** – The Penetration Testing Execution Standard suggests reviewing whether an application uses a common security framework. It implies that if an app leverages well-known centralized frameworks (like Spring Security, Express middleware, etc.), it’s less likely to have custom, inconsistent checks everywhere.",
    "Applicability": "Applies to complex applications with multiple components or teams. Simpler apps (small codebase) might inherently have “one place” for a control just because there’s only one. Mark N/A only if the application scope is so limited that there’s no chance for duplicate controls (e.g., a basic app where all security is naturally in one spot). Otherwise, any enterprise app or multi-service app should be evaluated on this front. If the organization has a security framework or uses a platform (like a CMS) that provides central controls, this item is about verifying they actually use it.",
    "Sources": "https://owasp.org/ASVS/Pages/Requirement_1.2_Authentication_Architectural#v123, https://www.iso.org/standard/73906.html"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "Authentication Architectural Requirements",
    "Item": "Verify availability of a secure coding checklist or policy for developers",
    "Description": "Check that developers have a defined secure coding standard or checklist to follow, and that it’s actually accessible and used. This could be an internal policy document or an industry standard (like CERT Java secure coding or OWASP Secure Coding Guidelines). The presence of such a checklist/policy means the organization has identified common security pitfalls and best practices and expects developers to adhere to them. It matters because without guidance, developers might unintentionally introduce vulnerabilities – a checklist institutionalizes lessons learned and known good practices (e.g., “Never store passwords in plaintext”, “Use parameterized queries for DB access”, etc.).",
    "Tools": "- **Policy Documentation Review**: Request the secure coding guidelines or policies from the organization. Evaluate if it covers relevant areas (authentication, access control, error handling, etc.) and if it’s up-to-date. A good checklist might map to OWASP ASVS or similar standards.\n- **Developer Interviews/Survey**: Ask a few developers if they are aware of a secure coding policy and where to find it. If they can’t, that’s a sign it exists only on paper or not at all. If they can, ask if it’s part of their code review checklist or QA.\n- **Code Review for Consistency**: If secure coding guidelines exist, their effect should be visible in code. For instance, if the policy says “use prepared statements for SQL”, you should not find raw string concatenation SQL queries in the code. By sampling the codebase for such patterns, you can gauge adherence and indirectly the presence of guidelines. Static analysis tools can help: run a scan (like **Semgrep** or **SonarQube**) for obvious insecure patterns. If many are present, either no checklist exists or it’s not followed.\n- **Build Pipeline Integration**: Check if the checklist’s rules are enforced via tools (e.g., linters or QA gates). For example, some organizations encode their secure coding rules into linting tools. If the CI pipeline has a stage referencing “security checks” or linter configs that align with a secure coding standard, that indicates a living policy.",
    "Links": "- **OWASP ASVS 1.2.4** – Mentions that an organization should have secure coding guidelines or checklist and that developers are trained in it. Essentially, ASVS expects a documented set of security requirements for developers.\n- **OWASP Secure Coding Practices Quick Reference** – This is a checklist-style document of secure coding practices. Many organizations adopt or tailor this as their internal policy. Its existence as an OWASP resource underscores the importance of having something similar in-house.\n- **NIST SP 800-218 (SSDF)** – Under **Practice PS.3** (Implement Secure Coding Practices), NIST’s guidance is to establish and maintain secure coding standards for developers. This aligns exactly with having a secure coding checklist/policy.",
    "Applicability": "Applicable to any development team writing code. Only N/A if the application is COTS (commercial off-the-shelf) and you have no influence on the developer practices, or perhaps if the development is outsourced and out of scope (though then the outsourcer should have a policy). In a typical app assessment, understanding if devs have a security checklist is always useful context, even if you can’t fully verify it. So usually not N/A for in-house development.",
    "Sources": "https://owasp.org/www-pdf-archive/OWASP_SCP_Quick_Reference_Guide_v2.pdf, https://csrc.nist.gov/Projects/ssdf"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "Access Control Architecture Requirements",
    "Item": "Verify trusted enforcement points such as access control gateways, servers etc enforce access controls",
    "Description": "Ensure that access control decisions are enforced by a trusted server-side component (or dedicated access control gateway), not left solely to the client or less reliable mechanisms. In practice, this means checks like “is user X allowed to do action Y?” happen on the server (or a centralized authorization service) that cannot be bypassed, as opposed to only in the UI or a mobile app. It also means using consistent enforcement points – for example, a middleware or gateway through which all requests pass and get authorized. This matters because if enforcement is done in an untrusted environment (like client-side JavaScript or a browser), attackers can manipulate it. And if enforcement is scattered (not centralized), some endpoints might be forgotten, leading to authorization bypasses.",
    "Tools": "- **Design Review**: Identify how and where the app performs authorization. Does the architecture include an API gateway or a central authZ service (like OAuth2 resource server, or a policy engine like OPA)? If yes, verify that all critical requests funnel through it. If some components talk to each other directly without going through the gateway, that’s a spot to examine further.\n- **Code/Config Inspection**: If you can review code, look for a common filter or interceptor that checks permissions on every request (e.g., a servlet filter in Java, or a global `@Authorize` annotation usage in controllers). The presence of a global access control mechanism indicates a central enforcement. Conversely, if each function manually implements access checks, there’s risk one is missed. Static analysis can sometimes find endpoints with no auth checks if most have one.\n- **Testing by Bypassing UI**: Try direct requests that mimic higher-privilege actions to see if server-side enforcement catches it. For example, if there’s an admin function not exposed in the UI for a normal user, directly call the admin API endpoint as a normal user. A proper enforcement point (like an access gateway) should reject it. If it succeeds, access control may only be enforced in the client (which is a flaw).\n- **Configuration Review**: For apps using external auth servers (like AWS Cognito, Okta, etc.), ensure that resource policies or gateway configs exist. For instance, check that your API Gateway has authorization enabled for each route. This is a kind of deployment check ensuring every entry point is covered by an auth policy.",
    "Links": "- **OWASP ASVS 1.3.1** – Requires that trusted enforcement points (like server-side or centralized components) are used for access control:contentReference[oaicite:39]{index=39}. It explicitly says to enforce access control in trusted locations, not on the client.\n- **OWASP WSTG – Authorization Testing**: The guide reiterates that one should test for enforcement on the server. Tests like *“Bypassing Authorization Schema”* (WSTG-ATHZ-02) assume there is a central check and we verify it’s in place by attempting to bypass it.\n- **CWE-602 (Client-Side Enforcement of Server-Side Security)** – This CWE highlights the mistake of enforcing security on the client side. The resolution is to do it on the trusted server side. It underpins why this check is important – to avoid CWE-602 scenarios.",
    "Applicability": "Always applicable for applications with user roles/permissions. If the app has no concept of users or roles (very rare for a web app), access control may not be in scope. Otherwise, any system where certain actions/data are restricted to certain users or roles should have a trusted enforcement point. Not applicable only if there literally are no access restrictions in the app (everything is public and equal), which is uncommon for non-trivial apps.",
    "Sources": "https://cwe.mitre.org/data/definitions/602.html, https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/05-Authorization_Testing/02-Testing_for_Bypassing_Authorization_Schema"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "Access Control Architecture Requirements",
    "Item": "Verify chosen control solution is flexible to meet application requirements",
    "Description": "Confirm that the access control mechanism or framework in use is flexible enough to express the app’s permission rules without developers resorting to ad-hoc workarounds. A flexible solution might mean a roles and permissions system that supports the complex rules the app needs (hierarchical roles, attribute-based access control, etc.). If the solution is too simplistic or rigid, developers might implement bypasses or duplicate checks to achieve what they need, which can introduce mistakes. Essentially, the access control system should align well with business requirements – e.g., if the app needs per-record ownership permissions, the chosen system should handle that via something like ABAC or contextual checks. Verifying this ensures the access control architecture will actually be used correctly everywhere, rather than circumvented in some parts of the code.",
    "Tools": "- **Requirements to Control Mapping**: Enumerate the types of access rules in the application (for instance: “Managers can approve expenses up to $1000”, “Users can only see their own orders unless they have role X”). Then examine the access control framework (or service) in place. Does it support rules of that nature? For example, if using a role-based system, can it easily express row-level ownership restrictions? If not, developers might implement those checks manually elsewhere – find those spots.\n- **Code Review**: Look for instances where developers wrote custom access logic rather than using the central system. E.g., if the app uses a standard @RoleAllowed annotation mostly, but you find functions with manual role checks (`if(user.role == 'ADMIN')` in code), that could indicate the standard solution didn’t cover that scenario. Each custom check is a potential flaw. Static analysis or grep can find such patterns.\n- **Developer Interviews**: Ask if any security requirements were hard to implement with the current ACL (Access Control List)/RBAC system. If they mention “Oh, the framework couldn’t do X so we had to do Y ourselves,” that points to inflexibility. Also ask if they maintain permissions in config or code and whether it’s cumbersome – if yes, they might bypass it for expediency.\n- **Policy Management Interface**: If the solution has a UI or config for managing permissions (like a central policy server), review how granular it is. A too-simplistic scheme (only high-level roles, no context of data) may not meet fine-grained needs. Check if there are “exceptions” or special-case code for specific scenarios; lots of exceptions can mean the system wasn’t a great fit.",
    "Links": "- **OWASP ASVS 1.3.2** – Implies that access control models should be capable of enforcing business rules (if a chosen model is too limited, it’s a design issue). While ASVS doesn’t explicitly say “flexible,” it does require that access control is sufficient and used uniformly.\n- **NIST SP 800-162 (Guide to ABAC)** – Discusses choosing attribute-based access control for complex policy requirements. The essence is matching the complexity of rules with the right framework. If an app’s needs are complex and ABAC is warranted, using a simple RBAC might fail. This NIST guide helps identify the right model for the requirements.\n- **OWASP Top 10 – A5 Broken Access Control**: Many examples of broken access control come from developers trying to implement checks outside a consistent framework (because the framework wasn’t fitting). The Top 10 commentary suggests using tested, appropriate access control mechanisms to avoid such gaps.",
    "Applicability": "This is a bit abstract, but applies to systems with non-trivial access rules. Simpler apps (e.g., just admin vs user) likely any standard solution fits, so flexibility isn’t a big concern. It becomes crucial when business rules are complex. Mark N/A if the access control requirements are very basic (so flexibility is moot) or if the app doesn’t really have roles/permissions (everything public or single-user app). Otherwise, especially in enterprise apps, ensure the access control design matches needs.",
    "Sources": "https://csrc.nist.gov/publications/detail/sp/800-162/final, https://owasp.org/Top10/A01_2021-Broken_Access_Control/"
  },
  {
    "Category": "Architecture, Design and Threat Modeling Requirements (V1)",
    "Sub Category": "Access Control Architecture Requirements",
    "Item": "Verify enforcement of principle of least privilege in functions, data files etc",
    "Description": "Check that throughout the application, users (or processes) only have the minimum access rights necessary to perform their tasks – no more. This principle of least privilege should be evident in how functions are exposed (e.g., regular users shouldn’t see admin functionalities), how data is segmented (a user can only access their own records by design), and how file access is handled (the app only can read/write files it absolutely needs). The goal is to limit potential damage if a user account or component is compromised. If this principle isn’t enforced, a low-privileged user might find ways (via direct object references, API calls, etc.) to perform unauthorized actions or read sensitive data, simply because the system didn’t restrict it.",
    "Tools": "- **Authorization Matrix**: Build or obtain a matrix of roles vs. features/data. Verify that the application’s UI and API adhere to this matrix (least privilege means most boxes in such a matrix are “No Access” except the minimal necessary ones). If no formal matrix exists, deduce one from requirements and test against it.\n- **Functional Testing**: As a lower-privileged user, attempt to perform actions reserved for higher roles (or system admins). For example, try accessing an admin-only URL or functionality. Use a tool like **Burp** to modify requests (change your role or user ID in requests) to see if the server side prevents it. E.g., attempt to retrieve someone else’s data by changing an identifier. Proper least privilege enforcement will result in an access denied or not found.\n- **File System Checks**: If you can access the server or if the app deals with file paths, verify that it doesn’t have access beyond what it needs. For instance, if the app should only serve images from `/app/uploads/`, try requesting `../` paths to see if it can read other files – it should be restricted (this crosses into path traversal testing, which is related). Also ensure any system accounts (from earlier check) have limited directory permissions on the OS.\n- **Code Review**: Look at how data access is implemented. If the code retrieves data without scoping by the current user or role (e.g., a query like `SELECT * FROM records` without a `WHERE user_id = ?`), that violates least privilege on data. Static analysis or manual review can catch missing filters in data queries that should enforce ownership.",
    "Links": "- **OWASP ASVS 1.3.3** – Focuses on least privilege enforcement for users and services. It says that users should only have access to what they require (no excessive privileges), implying checks at every layer to prevent privilege escalation.\n- **OWASP Top 10 – Broken Access Control**: Most broken access control issues (like IDOR, privilege escalation) are a result of not properly implementing least privilege. For instance, Insecure Direct Object References (IDOR) occur when the app fails to enforce that users can only access their own objects.\n- **Principle of Least Privilege (NIST)** – NIST guidelines repeatedly mention POLP in various contexts (user accounts, service accounts, firewall rules). NIST SP 800-53 has multiple controls (AC-6 Least Privilege, etc.) demanding that systems restrict permissions to the minimum necessary – reflecting this principle in application design too.",
    "Applicability": "Always applicable where there are multiple user roles or sensitive operations. If the application has a single user or no concept of roles (rare in multi-user systems), this might be less of a concern in that narrow sense, but even processes on the backend still should have least privilege. Generally, any system beyond trivial “one user does everything” should enforce least privilege and thus should be verified.",
    "Sources": "https://csrc.nist.gov/glossary/term/least_privilege, https://owasp.org/Top10/A01_2021-Broken_Access_Control/"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Session Management",
    "Item": "Session tokens within URL parameters (or error messages)",
    "Description": "Check that session identifiers (like session cookies or JWTs) are **not** exposed in URL query parameters or in error messages. Session tokens in URLs are problematic because URLs can be logged in browser history, server logs, or leaked via referer headers to third-party sites. Likewise, if error messages echo session tokens, an attacker could glean someone else’s token. A secure app will keep session tokens only in cookies or authorization headers – never as part of the URL or error text.",
    "Tools": "- **Crawl and Monitor URLs**: Use a proxy (Burp/ZAP) to crawl the application and see if any navigations or redirects include session IDs in the URL. For example, after login, does the app redirect to `home.jsp?jsessionid=<token>` (common in some older Java apps)? Or are there links like `?sessionToken=` anywhere. The proxy history or automated crawler can flag these.\n- **Review Error/Debug Output**: Intentionally generate some errors – e.g., alter a session cookie or make a malformed request – and see if the server returns any debug info that contains your session ID. If an error page or stack trace echoes back cookies or tokens (shouldn’t happen, but worth checking), that’s a leak. Similarly, some apps might include session IDs in custom error messages or logs that could be exposed.\n- **Browser Developer Tools**: Open DevTools and inspect network requests and responses. Look at any GET requests with query parameters, and check if any parameter looks like a token (long random strings, Base64/JWT format). Also check if `window.location` is ever set to a URL containing the session ID (some apps insecurely do this to transfer sessions, e.g., from HTTP to HTTPS – that’s legacy and insecure).\n- **Configuration**: If this is a known framework, check config settings. For example, Java J2EE servers can be configured to use URL rewriting for sessions (jsessionid in URL) when cookies are disabled. Ensure such options are off unless absolutely needed (and even then, it’s a risk).",
    "Links": "- **OWASP WSTG – Session Management Testing (Cookie/Session Token Handling)**: It notes to verify session tokens are only in cookies and not in URLs:contentReference[oaicite:50]{index=50}.\n- **OWASP ASVS 3.4** – States that session tokens should never be revealed in URLs or logs (to prevent leakage):contentReference[oaicite:51]{index=51}.\n- **NIST 800-63B (Section 7)** – While about session management guidelines, it implicitly advises protecting session secrets; putting them in URLs would violate secure session management principles outlined by NIST (like confidentiality of session authenticators).",
    "Applicability": "Relevant to all web applications using sessions or tokens. Only N/A if the application is completely stateless or doesn’t use session tokens at all. Even then, if any sensitive token (like an API key) could appear in a URL, it applies. In modern practice, session IDs in URL are mostly seen in old legacy apps or in a fallback for cookie-less scenarios, so especially check those. Otherwise, always ensure tokens aren’t in URLs by design.",
    "Sources": "https://owasp.org/ASVS/Session_Management#v33-session-id-not-in-the-url, https://datatracker.ietf.org/doc/html/rfc7231#section-7.3.1"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Session Login",
    "Item": "Login bypass",
    "Description": "Test that the authentication mechanism cannot be bypassed – meaning no alternative entry exists that lets a user establish a session or access privileged content without actually providing valid credentials. A login bypass could occur via multiple paths: an alternate URL that sets a session cookie, disabled pages that are still accessible, or parameter tampering that flips an authentication flag. Ensuring no login bypass exists is fundamental; otherwise, the entire session management and access control scheme can be rendered useless by an attacker simply skipping the login step.",
    "Tools": "- **Direct Resource Access**: After logging out (or without ever logging in), try to directly browse to pages or API endpoints that should require authentication. For example, access `/user/profile` or an admin URL and see if the application returns content or forces a redirect to login. Use Burp to modify requests if needed (e.g., removing cookies) and check responses. A proper application will respond with 401/403 or redirect to login for protected resources.\n- **Parameter Tampering**: Investigate the login request itself. Sometimes applications use hidden fields or parameters like `isAuthenticated=false` that the client passes. Attempt to modify such parameters (e.g., change `false` to `true`) and replay the request to see if the server mistakenly logs you in. Although rare, logic flaws of this nature have occurred.\n- **Alternate API or Old Endpoints**: If the app has an API, see if it enforces auth the same way as the main app. Try calling API endpoints without a token to check if they improperly grant access. Also, look for older versions of pages (like an `/old_login` or debug endpoints) that might accept a static password or no auth for testing purposes. Tools like **Burp Intruder** can fuzz common endpoint names (like `/login2`, `/debug/login`) to see if any respond differently.\n- **Session Fixation/Broken State**: Sometimes a login bypass can happen via session fixation – if you have a session ID and the server doesn’t invalidate it on login, possibly you can use an uninitialized session that magically becomes authenticated under certain conditions. Test by setting a session cookie (from a logged-out state) and then logging in with another account in another browser, see if any cross effects or if that session gains privileges unexpectedly. This is more of a logical/architecture test.",
    "Links": "- **OWASP WSTG – Bypassing Authentication Schema (WSTG-ATHN-04)**: Provides techniques to test if authentication can be circumvented by manipulating how the app handles sessions and login logic.\n- **OWASP ASVS 3.1** – Requires that all pages and functions enforce authentication if not specifically intended to be public. A login bypass often violates this if any sensitive page doesn’t properly enforce the check.\n- **OWASP Top 10 (Broken Authentication)** – Many broken authentication issues manifest as logic flaws allowing bypass (e.g., flawed state machine where multi-step login can be skipped). It highlights the need to test odd paths and unanticipated inputs that could bypass normal login.",
    "Applicability": "Applies to any application with a login. If the app has no login at all (completely public content), then there’s nothing to bypass (so N/A in that case). Otherwise, any auth system should be tested for bypasses. This includes multi-factor flows or SSO – ensure those can’t be short-circuited. Essentially always in scope when authentication exists.",
    "Sources": "https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/04-Authentication_Testing/05-Testing_for_Bypassing_Authentication, https://cwe.mitre.org/data/definitions/287.html"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Session Binding",
    "Item": "Application doesn't generate new session token on authentication",
    "Description": "Verify that upon a successful login (or privilege level change), the application issues a brand new session identifier instead of reusing an existing one. If the app fails to do this (i.e., it keeps the same session ID after login), it’s vulnerable to **session fixation**. In a session fixation attack, an attacker tricks a user into using a known session ID (perhaps by supplying a link with that ID); if the app doesn’t renew the session at login, the attacker can then hijack the user’s session after they authenticate. Therefore, regenerating the session ID at auth time is critical to bind the session to the authenticated user securely.",
    "Tools": "- **Manual Session Observation**: Using Burp Suite or browser dev tools, note the session cookie value (e.g., JSESSIONID, PHPSESSID) before login and then immediately after a successful login. If it’s exactly the same, that’s a finding. Burp’s Proxy history or the browser’s storage can show you the cookie pre- and post-auth.\n- **Automated**: You can write a small script or use **OWASP ZAP** to perform a login and capture cookies before and after. ZAP has an active scan rule for session fixation that will alert if session tokens aren’t changed after login.\n- **Multiple Login Attempts**: Log in, log out, log in again and see if the app sometimes reuses session IDs. It should issue a new one every time. Also check alternate flows (like logging in via OAuth/OIDC redirect) to ensure those too result in a new token.\n- **Session Fixation Test**: As a more advanced test, do the following: In one browser (attacker), initiate an anonymous session (get a session ID). Then somehow inject that ID into the victim’s browser (maybe by sending a link like `https://site.com;jsessionid=ATTACKERID`). Have the victim log in. If you as attacker now find that session ID grants you the victim’s authenticated session, the app is not regenerating the ID. This test must be done carefully and only in a controlled environment. But it directly demonstrates the risk if regeneration is not done.",
    "Links": "- **OWASP ASVS 3.1.2** – Specifies that the session ID should be changed upon login (and other privilege changes). It’s a must-have for secure session management.\n- **OWASP WSTG – Session Fixation Testing (WSTG-SESS-05)**: Describes testing steps similar to above to check if a new session is created after authentication.\n- **MITRE CWE-384** – “Session Fixation” entry which explains the weakness of not renewing session IDs and the importance of regenerating them at auth boundaries.",
    "Applicability": "Applicable whenever the application uses session identifiers or tokens to track user state. Virtually all web apps with logins do, except maybe those using stateless JWTs (even then, a new JWT should be issued at login, so conceptually similar). So test this for any cookie-based or token-based session scheme. Only not applicable if there is literally no session concept (e.g., HTTP Basic Auth on every request – even then, you could argue a new nonce realm would be nice, but that’s an edge case).",
    "Sources": "https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/06-Session_Management_Testing/03-Testing_for_Session_Fixation, https://cwe.mitre.org/data/definitions/384.html"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Session Binding",
    "Item": "Auth tokens with less than 64 bits of entropy",
    "Description": "Verify that session identifiers or authentication tokens are sufficiently long and random – generally at least 64 bits of entropy (which typically means 16+ random bytes, often represented as 32+ hex characters). Tokens with less entropy are vulnerable to brute-force guessing. If an attacker can guess or predict a session token, they can hijack sessions without needing credentials. Ensuring high entropy (64 bits ~ 1.8e19 possibilities or more) makes brute forcing impractical with modern computing power.",
    "Tools": "- **Token Length Check**: Examine a sample session token (session cookie, JWT ID, etc.). Note its length and format. For example, a classic JSESSIONID might be something like `ABC123...` of a certain length. If it’s shorter than, say, 16 bytes (32 hex chars), flag it. JWTs are larger but they include other data; focus on the secret portion (JWT secret or signature strength). Some tools can decode JWT and show the `jti` (token ID) if present.\n- **Burp Suite (Sequencer)**: Use Burp’s Sequencer on session tokens. Capture, say, 100+ session tokens by repeatedly hitting the app’s login (or a token endpoint), then feed them to Sequencer. It will perform an entropy analysis (Chi-square tests, etc.) and estimate the randomness. Sequencer will highlight if the token appears predictable or has less than ideal entropy in certain bits.\n- **Manual Analysis**: If you can’t automate, even observing the token format helps. For instance, if you see a session ID like `USER12345` or something guessable (like incremental numbers, or a username embedded), that’s clearly insufficient entropy. Many modern frameworks generate strong tokens, but older ones or custom implementations might not.\n- **Review Crypto**: If you have access to code or config, see what PRNG or algorithm is used for tokens. Secure tokens should come from a cryptographically secure random generator (e.g., `SecureRandom` in Java, `crypto.randomBytes` in Node). If you find something like `rand()` or a timestamp used, that’s insecure. Static analysis tools can pinpoint usage of weak random number generators for security-sensitive tokens.",
    "Links": "- **OWASP ASVS 3.1.4** – Specifies at least 64 bits of entropy for session identifiers. This is an explicit requirement to thwart guessing attacks.\n- **OWASP WSTG – Session Predictability**: Guides testing the randomness of session tokens using tools like Burp Sequencer, which correlates with this check.\n- **NIST SP 800-63B** – Digital Identity Guidelines state session cookies (session authenticators) should be at least 64 bits of entropy and generated with a CSPRNG. NIST emphasizes high entropy to mitigate guessing.",
    "Applicability": "Applies to any system issuing session IDs or tokens. Only not applicable if no session concept exists (which is rare in web apps). Even APIs using API keys or JWTs: those tokens/secrets should also have high entropy. So essentially, always check this for web sessions and persistent auth tokens. It’s fundamental to session security.",
    "Sources": "https://owasp.org/ASVS/Session_Management#v314-session-id-entropy, https://portswigger.net/burp/documentation/desktop/tools/sequencer"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Session Binding",
    "Item": "Auth tokens not stored securely (e.g. not a cookie or session storage)",
    "Description": "Ensure that authentication tokens (session IDs, JWTs, API tokens) are stored in a secure manner on the client side. They should be kept in a place not easily accessible by malicious scripts – typically **HTTP-only cookies** for web sessions, or secure platform storage for mobile (rather than insecure locations like HTML5 localStorage for long-term tokens). If tokens are stored inappropriately, it increases risk that XSS or other client-side attacks can steal them, or that they leak in browser data (like tokens in localStorage might be exfiltrated if any XSS exists). In short, the binding of the token to a secure storage mechanism is vital for session security.",
    "Tools": "- **Browser Inspection**: Open the application in a browser and use developer tools to check where the token resides. After logging in, look in **Application -> Storage**: check Cookies for session tokens and check Local Storage/Session Storage for any tokens. If you find, say, an `authToken` or `JWT` in localStorage or sessionStorage, that’s a less secure pattern (susceptible to XSS). Ideally, tokens should be in cookies with the HttpOnly flag (so they don’t show up in JS-accessible storage at all).\n- **Review Network Calls**: Observe how the token is sent. If it’s in an `Authorization: Bearer <token>` header, then the app likely stored it in a JS variable or storage. Figure out where by searching in the code for how that header is added (if code is accessible). That will lead you to where the token lives (often localStorage for SPAs using bearer tokens). If it’s a cookie (check request headers for Cookie: sessionId), verify that cookie has **HttpOnly** and **Secure** flags set, and it’s not accessible via client JS.\n- **XSS Simulation**: If possible (in a test environment), introduce a benign XSS (like using the browser console or a custom script injection) to attempt reading document.cookie or localStorage. If the session token is HttpOnly cookie, `document.cookie` won’t show it, which is good. If the token is in localStorage, `localStorage.getItem('token')` would retrieve it – showing vulnerability if any XSS occurs. This simulates what an attacker could do if XSS is ever found: if tokens are in JS-accessible storage, they’d be compromised.\n- **Mobile App Check**: If relevant (say the token is used in a mobile app), ensure it’s using the platform’s secure storage (like iOS Keychain or Android Secure Shared Preferences) rather than storing in plain-text preferences or logs.",
    "Links": "- **OWASP ASVS 3.2** – States session tokens or auth credentials must be stored securely (HttpOnly cookies for web). It discourages storing tokens in places accessible to JavaScript (because of XSS risk).\n- **OWASP JWT Cheat Sheet** – Advises against storing JWTs in localStorage due to XSS; recommends HttpOnly cookies for web JWT usage. This ties into this verification: the token storage strategy should prioritize security over convenience.\n- **OWASP Top 10 – A3 Sensitive Data Exposure**: Includes improperly stored tokens as an example of sensitive data exposure. If tokens are not stored with adequate protection, they can be leaked or stolen, leading to full account compromise.",
    "Applicability": "Applicable to web applications and any client that stores session or auth tokens. If an app truly doesn’t use tokens (e.g., it’s using HTTP Basic Auth each time, so nothing persists), then this might be N/A. But that’s rare; most have a session mechanism. Single Page Applications using JWTs are particularly in scope – ensure they aren’t using localStorage if security is a concern. Traditional web apps should use cookies correctly. So essentially, check this in all normal scenarios.",
    "Sources": "https://owasp.org/www-project-cheat-sheets/cheatsheets/JSON_Web_Token_Cheat_Sheet_for_Java.html#token-storage, https://datatracker.ietf.org/doc/html/rfc6275#section-5.3"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Session Binding",
    "Item": "Auth tokens generated with poor cryptography",
    "Description": "Assess if session tokens or auth tokens are generated using strong cryptographic algorithms and libraries. “Poor cryptography” in token generation could mean using outdated hashing (like MD5) or predictable algorithms to construct tokens (like encrypted but not signed tokens, or using a weak random number generator). For example, some apps might create session IDs by encrypting user information with a static key – if weak, an attacker could forge a token. Or using a weak PRNG could produce guessable tokens. We want tokens that are essentially random and unforgeable. So this verification overlaps with entropy but also looks at *how* the token is built (ensuring modern cryptographic practices).",
    "Tools": "- **Token Structure Analysis**: Inspect a few tokens (session IDs, JWTs, etc.). If it’s a JWT, decode the header and payload – check the algorithm (e.g., `alg: HS256` vs `alg: none` or a known weak algo). HS256 (HMAC-SHA256) is fine if the secret is strong; RSA/ECDSA are fine too. If you see `alg: none` or something like HSMD5 (not standard, but older systems might do weird things), that’s a flag. For opaque session IDs, see if they contain any Base64-encoded data (which might hint at being something like user data encrypted/base64’d). If so, attempt to decrypt or recognize patterns – but this often requires known keys.\n- **Known Patterns and Default Secrets**: Some frameworks had issues where they used a default static secret for tokens (e.g., older JWT libraries defaulting to “secret”). If you have source access, search for token generation code and see if secrets/keys are properly randomized and stored securely. If not, an attacker might brute force or guess tokens if the crypto key is weak or reused.\n- **Brute Forcing Attempts**: For a suspected weak scheme, you could attempt offline cracking. For instance, if session IDs look like `SHA1(user_email || timestamp)`, an attacker could guess them by hashing known values. Use tools like **Hashcat** or custom scripts if you deduce a pattern. This is only feasible if you get a strong hint of structure.\n- **Crypto Library Use**: Check what crypto library and functions are used. If the app uses a modern secure library (OpenSSL, bcrypt for any token derivation, etc.), that’s good. If you find custom crypto code (e.g., homemade cipher or base64 encoding used as “encryption”), that’s bad. Static analysis can find usage of outdated crypto (MD4, MD5, SHA1 for critical stuff) – for instance, many scanners will flag MD5 usage in session or password context as a weakness.",
    "Links": "- **OWASP ASVS 3.1 & 3.2** – These collectively imply that session tokens should be generated with secure random and cryptographic techniques (no homebrew or weak algos). ASVS v3 doesn’t explicitly list “no weak crypto in tokens,” but in V6 (Cryptography) and general principles, it mandates strong algorithms.\n- **CWE-326 (Inadequate Encryption Strength)** – If an auth token is generated by encryption with a weak key or algorithm, it’s a form of CWE-326. Similarly, **CWE-338 (Weak PRNG)** covers using non-cryptographic random for tokens.\n- **NIST SP 800-63B** – Requires session authenticators (like cookies or tokens) to be generated by secure random processes and, if applicable, using approved cryptographic random number generation. It effectively prohibits using known weak algorithms for any part of token generation.",
    "Applicability": "This is relevant to any application creating session or auth tokens. If tokens are simple random cookies from a known-good framework, this is often fine; but custom tokens or older systems are at risk. Only mark N/A if the application truly uses no tokens (again, rare). Even APIs issuing API keys need this (the key generation should be strong). So in practice, nearly all apps with sessions or API auth fall under this check.",
    "Sources": "https://cwe.mitre.org/data/definitions/338.html, https://cheatsheetseries.owasp.org/cheatsheets/Cryptographic_Storage_Cheat_Sheet.html"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Session Logout",
    "Item": "Session Expiration after logout",
    "Description": "Verify that when a user logs out, their session is fully terminated server-side (and ideally client-side cookie deleted) so it cannot be reused. The goal is that logout actually invalidates the session token, making it useless if an attacker somehow obtained it. We are confirming that the application properly destroys session state on logout. If it doesn’t, an attacker with the token (from shoulder-surfing, token theft, etc.) could continue to act as that user even after they believe they logged out.",
    "Tools": "- **Functional Test**: Log in as a user, perform some action to confirm the session is active, then log out. After logging out, attempt to use the same session token (e.g., via Burp) to perform an action or access a page. This can be done by intercepting a request post-logout, replacing the new token (if any) with the old one, or preventing your client from clearing the cookie. If the server responds normally (not forcing re-auth), then logout didn’t invalidate it properly. A correct implementation yields an invalid session (you’d get kicked to login or a 401 response) when reusing a logged-out token.\n- **Multiple Device Scenario**: Login on two separate browsers (or browser and incognito as the same user account, if the app allows concurrent sessions). Then logout in one of them. See if the other session is affected or not. Many apps won’t kill other concurrent sessions on a single logout – that’s usually fine (addressed in another item). Here, focus on the specific session that was logged out: ensure it’s dead. So, in the browser where you did not click logout, try to use that session – if it’s still active, that might indicate that logout in one client doesn’t invalidate sessions in others (which could be design or a flaw). Typically, logout is per session, not global, so this might be expected. Just ensure the session that triggered logout is gone.\n- **Check Cookie/Token Deletion**: Observe if the app set the session cookie’s expiration to an old date or sent a Set-Cookie to remove it. That’s the client side. And/or if using JWT, there’s often no client deletion (the client just drops it). But server-side, perhaps through an API call, the token should be marked invalid. Without direct server insight, rely on testing access as above.\n- **Server-Side Session Store**: If you have any access to server (white-box), check if the session ID is removed from the session store (in-memory table, database, etc.) upon logout. If you see it still present marked active, that’s an issue. But often, you won't have this access on a black-box test, so stick to behavioral testing.",
    "Links": "- **OWASP ASVS 3.3.2** – Requires that logout or other session termination actions invalidate the session on the server. It also implies subsequent use of that session must be rejected.\n- **OWASP WSTG – Testing for Logout Functionality (WSTG-SESS-06)**: Describes ensuring that after logout the session cannot be used:contentReference[oaicite:74]{index=74}. It often mentions trying to reuse cookies after logout to verify invalidation.\n- **NIST 800-63B** – Session termination guidelines (section 7) indicate that sessions should be invalidated at logout or after a defined timeout. While user-initiated logout specifically should disallow further use of that session ID.",
    "Applicability": "Applies to any application with a logout feature (which should be all apps with sessions). If an app has no logout (some long-lived token scenarios or stateless auth might not have explicit logout), then consider this N/A but note it as a design concern if appropriate. Otherwise, always test logout effectiveness.",
    "Sources": "https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/06-Session_Management_Testing/06-Testing_for_Logout_Functionality, https://datatracker.ietf.org/doc/html/rfc7235#section-3.1"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Session Logout",
    "Item": "Application should force users to re-auth after an appropriate idle time",
    "Description": "Confirm that the application implements an **idle session timeout** – i.e., if a user is inactive for a defined period (say 15 minutes, 30 minutes, etc.), the session expires and the user must log in again. This is crucial to reduce the window in which a stolen or unattended session could be abused. If a user walks away or forgets to log out, an idle timeout limits how long that session remains usable. Without it, sessions could live indefinitely (or until absolute timeout) even with no activity, which is riskier. We need to ensure the timeout is of reasonable length per the app’s sensitivity and that it actually works.",
    "Tools": "- **Configuration Inquiry**: Often, idle timeout is configured on the server side (in a config file or app settings). For example, Java web.xml might have `<session-timeout>30</session-timeout>` in minutes. If you have access to such config or documentation, verify the value. Otherwise, proceed to testing.\n- **Active vs Idle Behavior**: Log in as a user and then remain idle (do nothing) for just over the expected timeout threshold. Then attempt an action. You can simulate this in testing by using Burp: note the session cookie, wait out the timeout period (or manually adjust your system time if testing locally). After the wait, send a request with the old session cookie. If the server responds with a redirect to login or a session-expired message, it’s working. If it still allows the action, there’s no (or too long) idle timeout. Alternatively, some apps implement this on the client side with JavaScript; disable or watch for any client scripts that might ping the server (to keep-alive) or show a timeout warning.\n- **Shorten Timeout for Test**: If possible on a test environment, reduce the idle timeout to something short (like 1 minute), then test quickly to confirm it triggers. This might require config changes or using a demo mode.\n- **Session Store Observation**: If you can see server session data, check last access timestamps getting updated with activity. An idle timeout logic will track last activity and compare current time. Without direct access, rely on black-box method above.",
    "Links": "- **OWASP ASVS 3.2.1** – Specifies an idle timeout (typically 15-30 minutes) for sessions. It’s a requirement for secure session management that idle sessions end.\n- **OWASP WSTG – Testing for Session Timeout (WSTG-SESS-07)**: Guides verifying both idle and absolute timeouts by waiting and checking if the session expires.\n- **NIST 800-63B** – Recommends session timeouts as a mitigation for session hijacking. NIST suggests reasonable timeouts based on risk (for example, high-risk apps might log out sooner). While it doesn’t mandate a specific time in all cases, it emphasizes the need for one.",
    "Applicability": "Virtually all web apps with sessions. Only slight exceptions: some real-time systems or kiosk modes where continuous login is needed (even then, they often use other controls). If an app explicitly chooses no timeout (like “keep me logged in” features), it should still implement some extended timeout or inactivity detection. So this should be checked for essentially every app session.",
    "Sources": "https://owasp.org/ASVS/Session_Management#v32-session-expiration, https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/06-Session_Management_Testing/07-Testing_for_Session_Timeout"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Session Logout",
    "Item": "Application terminates other sessions after password change",
    "Description": "Verify that when a user performs a sensitive account change – specifically changing their password – the application invalidates any other active sessions that the user had. This is a security measure to mitigate the scenario where an attacker has stolen a user’s session; if the user realizes and changes their password, all prior sessions (possibly hijacked) should be logged out, forcing re-authentication with the new credentials. If the app does not terminate existing sessions on credential reset/change, an attacker who already hijacked a session could continue to use it even after the user’s password is changed.",
    "Tools": "- **Multiple Session Test**: Log in with the same account from two different browsers/devices (or one normal window and one incognito, to simulate separate sessions). On one of them, perform a password change. Then, on the other session (which you haven’t touched), try to perform any action or navigate to a page. Expected result: that session should now be invalidated – the server should treat it as expired or ask for login again. If you can still use it normally, the sessions were not terminated.\n- **API or Cookie Inspection**: After password change, sometimes apps will change a session token or issue a new one. Check if a new session cookie is set in the response to the password-change request. If yes, that suggests the old tokens might be invalid. But still test the old one as above to confirm. If no new token and old session remains, likely other sessions remain too.\n- **Review Security Settings**: Some applications have an option “log me out of other devices” either automatically on sensitive changes or as a user-selectable feature. Check account settings or security settings for wording like “sign out of all other sessions” after password change. If it’s present and default, ensure it works; if absent, note that as a potential gap.\n- **Server Session Store**: If accessible, observe that on password change event, all session entries for that user are removed (except possibly the current one issued anew). Without server access, the above active test is the way to verify.",
    "Links": "- **OWASP ASVS 2.2.4** (though an Authentication requirement) – It suggests that on password change or other credential reset, the application should invalidate existing sessions and session tokens. This maps to the requirement here in session management context.\n- **NIST 800-63B Sec. 7.2** – While mostly about session binding, it notes that verifiers (the app) should terminate session tokens when credentials are changed as part of good session lifecycle management.\n- **OWASP Top 10 – A2 Broken Authentication**: Failing to invalidate sessions after password changes can be considered part of broken session management, and is often mentioned in security guidelines as a necessary step to contain damage from account compromise.",
    "Applicability": "Applicable to any application where users can change credentials (password, keys, etc.) and have concurrent sessions (e.g., logged in from multiple devices). If an app is single-session only (logging in somewhere automatically logs you out elsewhere), then this is inherently taken care of. But most modern apps allow multiple sessions, so this check is important. If the app does not allow password changes (rare), mark N/A; otherwise assume it should be in place for web/mobile apps.",
    "Sources": "https://owasp.org/ASVS/Authentication_Verification_Requirements#v224-session-invalidation-on-password-change, https://cheatsheetseries.owasp.org/cheatsheets/Session_Management_Cheat_Sheet.html#session-invalidation"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Session Logout",
    "Item": "Users have option to log out on other devices (session fixation)",
    "Description": "Ideally, provide users with the ability to view and terminate active sessions on other devices. This item is phrased a bit strangely with “(session fixation)” – likely they mean session management issues related to multiple sessions. The core is that a user should have control to explicitly log out other sessions (for example, a “Log out of all other sessions” feature or a dashboard listing active sessions/browsers). This is a defense-in-depth against stolen sessions or just a convenient security feature. If an application offers this, verify it works; if not, it’s a nice-to-have that some standards (like ASVS) encourage.",
    "Tools": "- **UI Examination**: Check the account/security settings page for any feature that lists active sessions or devices. It might show last login locations, and options to revoke them. If present, test it: log in from two devices, then use the feature to log out other sessions, and confirm the other session is indeed terminated (similar to the previous test for password change, but using the user-initiated control now).\n- **Direct Request**: If no UI but an API exists (some apps have an API endpoint to kill sessions, even if not exposed), you might find hints in the JavaScript or mobile app code. Not typical to hide it though; usually, if available, it’s visible.\n- **Session Fixation Tie-in**: The mention of session fixation might be implying that if the user suspects an issue, they could terminate a possibly fixed session. But to test session fixation (already covered above), having the ability to kill sessions helps mitigate it. So, if the feature exists, one could simulate a fixation scenario, then use it to kill that session.\n- **Code/Config**: In some frameworks, this feature can be configuration (like token-based auth where you can revoke tokens by ID). Without UI, if you have code access, see if there’s any function or admin capability to revoke sessions. If not, then users don’t have that control.",
    "Links": "- **OWASP ASVS 3.3.3** – Recommends that users have the ability to view and log out other sessions/devices. It’s a requirement at higher ASVS levels (for defense in depth) to provide an interface for session management to the user.\n- **OWASP Session Management Cheat Sheet** – Mentions implementing an account activity feature and allowing session revocation as a best practice for critical applications.\n- **User Account Security Guidelines (Various)** – Many security standards (e.g., CIS benchmarks for web apps) advise providing users with control over their sessions. It’s not always mandatory, but seen as a good security usability feature.",
    "Applicability": "This is a feature rather than a pure vulnerability. Not every app will have it. It’s more common in sensitive applications (banking, email, social networks). If the app’s threat model includes session theft risks, this feature is highly relevant. For simple apps, absence isn’t a fail, it’s just not implemented. Mark N/A if the application does not support multiple concurrent sessions or it’s out-of-scope to evaluate user features. Otherwise, if it’s supposed to exist, test it.",
    "Sources": "https://owasp.org/ASVS/Session_Management#v333-manage-other-sessions, https://www.rfc-editor.org/rfc/rfc6819#section-5.2.2.3"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Cookies",
    "Item": "Auth cookies should have the Secure attribute",
    "Description": "Ensure that session cookies (and any sensitive cookies like JWT cookies) are set with the **Secure** flag. The Secure attribute instructs the browser to only send the cookie over HTTPS connections, never over plaintext HTTP. Without it, if an attacker can trick a user into making an HTTP request (or if the user ever visits the site via HTTP), the cookie could be transmitted in cleartext and stolen. So, Secure flag is essential for confidentiality of the session token in transit.",
    "Tools": "- **Browser Developer Tools/Proxy**: Inspect the Set-Cookie header when logging in or receiving a session cookie. In the response from the server that sets the session cookie, it should look like `Set-Cookie: JSESSIONID=abc123; Path=/; Secure; HttpOnly`. Specifically verify **Secure** is present. Also check any subsequent requests in Burp or browser – the cookie should not be sent over an `http://` URL (test by attempting to access an HTTP version of the site; ideally it redirects to HTTPS before setting cookies, or simply doesn’t allow HTTP at all).\n- **Configuration Review**: If you have config files (e.g., in Tomcat, secure cookies can be enforced, in .NET `<httpCookies requireSSL=\"true\"/>`), check those. Similarly, frameworks often have a setting. Ensure it’s turned on in production.\n- **HTTPS Enforcement**: The presence of Secure flag is moot if the site is accessible via HTTP and sets cookies there. So also confirm the application forces HTTPS site-wide (e.g., via HSTS and redirects). But the flag itself is still needed even if you normally redirect, as a misconfigured subdomain or user manually typing http could cause a leak. Some testing can include hitting an HTTP endpoint deliberately to see if the cookie ever comes through (it should not if Secure is working and the browser is respecting it, but if the server mistakenly sets a cookie without Secure on HTTP, that’s really bad).",
    "Links": "- **OWASP ASVS 3.4.2** – Requires that session cookies are marked Secure, ensuring they aren’t sent over unencrypted channels.\n- **OWASP WSTG – Testing for Cookies Attributes (WSTG-SESS-16)**: Instructs to verify Secure (and HttpOnly, etc.) on cookies.\n- **RFC 6265 (Cookie Spec)** – Recommends Secure for any cookie that needs confidentiality. Modern browsers also often default to not sending cookies in mixed content, but that’s not foolproof unless flagged.",
    "Applicability": "All web applications using cookies for authentication. If the app uses only tokens in Authorization header and no cookies, this might be N/A for cookies (but those tokens should be sent over TLS anyway). Practically, any cookie that maintains session or sensitive state should have Secure. Only N/A if the application never transmits sensitive info via cookie (rare in modern auth, but e.g. if only using localStorage tokens – then check those via other items).",
    "Sources": "https://owasp.org/ASVS/Session_Management#v342-cookie-flags, https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie#secure"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Cookies",
    "Item": "Auth cookies should have the HTTPOnly attribute",
    "Description": "Verify that session cookies are marked **HttpOnly**, meaning they are inaccessible to client-side scripts (JavaScript). This flag helps mitigate the impact of cross-site scripting (XSS) vulnerabilities by preventing malicious scripts from reading the cookie’s value. Without HttpOnly, if XSS is present, the attacker could steal the session ID via `document.cookie`. HttpOnly greatly reduces that risk, as the browser will not reveal the cookie to JavaScript.",
    "Tools": "- **Check Set-Cookie Headers**: Similar to checking Secure, look at the `Set-Cookie` header for the session token and ensure `HttpOnly` is present. In Chrome DevTools, cookies marked HttpOnly will be indicated and not accessible via `document.cookie`. You can also test manually: open the browser console after logging in and try `document.cookie` – see if the auth cookie name appears. If HttpOnly is properly set, it will not show up in that output.\n- **Browser Developer Tools**: In the storage view, HttpOnly cookies are often flagged or not directly editable via JS. But easiest is the console method above.\n- **XSS Simulation**: If you want to be thorough, simulate an XSS by injecting a script (in a test environment or via browser console) that tries to send `document.cookie` to yourself. If the session cookie doesn’t come along (but you do see other non-HttpOnly cookies maybe), that indicates success. Typically, just observing the flag in Set-Cookie is enough.\n- **Configuration/Code**: Confirm the web framework is set to HttpOnly by default for session cookies. Most modern frameworks do this automatically, but legacy or custom cookie-setting might not. For example, in some Java frameworks you call `cookie.setHttpOnly(true)`. If reviewing code, ensure that’s done for any custom cookie carrying sensitive data.",
    "Links": "- **OWASP ASVS 3.4.1** – Requires cookies with sensitive info (like session IDs) to be HttpOnly.\n- **OWASP WSTG – Testing for HttpOnly**: Part of the cookie attribute testing, ensures HttpOnly is set.\n- **OWASP Cheat Sheet – XSS**: Recommends HttpOnly as a defense in depth to protect session cookies from being stolen by XSS (though it’s not a fix for XSS itself, it mitigates impact).",
    "Applicability": "Any web app using cookies for session or sensitive tokens. There’s essentially no reason not to set HttpOnly on a session cookie. If the app genuinely needs to read the cookie via JS (which is a design smell for session cookies), that’s the only case HttpOnly might be omitted – and then you should question why. Otherwise, mark N/A only if no cookies in use. If using an alternate auth scheme (e.g., all tokens via JS), then HttpOnly isn’t applicable to cookies but the risk (token theft via XSS) still exists differently. For cookie-based sessions – always applicable.",
    "Sources": "https://owasp.org/ASVS/Session_Management#v341-httponly-flag, https://owasp.org/www-community/HttpOnly"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Cookies",
    "Item": "Auth cookies have the SameSite attribute to prevent CSRF",
    "Description": "Check that session cookies (and other security-sensitive cookies) use the **SameSite** attribute, preferably `SameSite=Lax` or `Strict` (or `None` if cross-site usage is needed and then must be Secure). SameSite instructs browsers to not send the cookie on cross-site requests (depending on mode), which is a built-in mitigation against CSRF attacks. For example, with SameSite=Lax, cookies won’t be sent on cross-origin POST requests, making CSRF much harder. If this attribute is absent, the app is relying solely on anti-CSRF tokens or nothing at all for CSRF defense, which may be okay if tokens exist, but adding SameSite is defense-in-depth and now a best practice.",
    "Tools": "- **Observe Set-Cookie**: Look at the `Set-Cookie` header for the session cookie and see if `SameSite` is present and what value it has. Modern browsers also show SameSite in the storage or network tab. If it’s missing entirely, that’s a finding in terms of “should be set”. If it’s present, note if it’s Lax, Strict, or None. “None” must be paired with Secure and typically indicates the app needs cross-site usage (like third-party APIs or multiple subdomains). “Lax” is usually a good default for most web apps (it stops cross-site POSTs from carrying the cookie, while still allowing navigational GETs with the cookie).\n- **Behavior Test**: If feasible, simulate a cross-site request (CSRF scenario) to see if the cookie is withheld. For instance, create a simple HTML page on another domain with a form pointing to the target app’s state-changing action. If SameSite is working (Lax), and you use a normal link or GET form, cookies might still send on top-level navigation (Lax allows some cases). If Strict, no cookies on any cross-site navigation. But if testing manually is cumbersome, trust the attribute presence is enough evidence.\n- **Browser Defaults**: Note that newer browsers default to Lax if SameSite isn’t specified (as of 2020+). However, relying on defaults isn’t best practice; explicitly setting it is clearer. If the application doesn’t explicitly set it, the browser likely treats it as Lax now. But older browsers and some contexts might treat missing as None. So it’s better the app specifies it.\n- **Config Check**: Many frameworks allow setting SameSite globally. Check config files for such settings (e.g., in .NET `cookie.SameSite = SameSiteMode.Lax`). Ensure it’s not left as the older default (None) in frameworks where default might not have updated.",
    "Links": "- **OWASP ASVS 3.4.3** – Specifies that session cookies should use SameSite to mitigate CSRF.\n- **OWASP Cheat Sheet – CSRF**: Recommends enabling SameSite on cookies as an additional protection layer against CSRF attacks, noting modern support across browsers.\n- **Mozilla Developer Network** – Provides guidance on SameSite usage and the differences between Strict/Lax/None, reinforcing why this attribute is important for session cookies used in authentication.",
    "Applicability": "Applies to web apps using cookies for authentication/session. If the app does not use cookies at all (token in header scenario), then SameSite isn’t directly applicable to the token (CSRF protection then relies on other means). Most traditional web apps with forms and cookies should use SameSite. Mark N/A only if truly no cookies. If the app has cross-domain use cases (like third-party login or subdomains), it may set SameSite=None with Secure, which is okay if intentional. The key is it shouldn’t be just missing without reason.",
    "Sources": "https://owasp.org/ASVS/Session_Management#v343-samesite-flag, https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie/SameSite"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Cookies",
    "Item": "Auth cookies have the __Host prefix",
    "Description": "If possible, session cookies should use the `__Host-` prefix in their name, which is a newer standard that enforces certain security properties: a `__Host-` cookie must be Secure, cannot have a domain specified (meaning it’s only valid for the host that set it), and path must be `/`. For example, naming a cookie `__Host-sessionId` and meeting those criteria ensures it’s not accessible as a subdomain cookie and is always secure. This check is to verify if the application is using this best practice naming convention for cookies, which provides additional safety. It’s not very common yet but is recommended by security standards.",
    "Tools": "- **Cookie Name Inspection**: See if the session cookie’s name begins with `__Host-`. E.g., `__Host-session` or similar. If it does, great – then also confirm it’s Secure, no Domain attribute, and Path=/ (these are automatically enforced by browsers when they see `__Host-`, but double-check server isn’t sending a Domain attribute by mistake, which would cause the cookie to be rejected or ignored by modern browsers). If the cookie name doesn’t have that prefix, this is just a recommendation that isn’t implemented – which is common. It would then be an “opportunity for improvement” rather than a critical flaw, assuming other flags are set.\n- **Browser behavior**: If a cookie does use __Host-, try setting a similar cookie manually in the browser console with Domain= or Path not root, and notice that the browser will refuse or adjust it. This demonstrates the protective effect. But this is more academic; just noting the prefix usage is usually enough.\n- **Documentation/Config**: Check if the application or framework has an option to set cookies with the __Host prefix. Some frameworks might not support it by default. If it doesn’t, its absence is not a fail; it’s just not using an additional safeguard. If it’s supposed to (maybe a security hardening guideline of the company said to do it), then it’s noteworthy.\n- **Subdomain Consideration**: Also see if they maybe use `__Secure-` prefix instead (another prefix with slightly less strict rules). `__Secure-` requires Secure flag but not the host scope restriction. __Host- is stronger. Neither prefix is extremely widespread, but if used, good. If not, maybe suggest it.",
    "Links": "- **OWASP ASVS 3.4.4** – Mentions using cookie prefixes like __Host- for session cookies to harden them.\n- **RFC 6265bis (draft)** – Defines the `__Host-` and `__Secure-` prefixes. __Host- ensures cookie is tied to the host and not a parent domain, mitigating certain cookie injection attacks and scope confusion.\n- **OWASP Cheat Sheet – Session Management**: Advanced recommendation to use `__Host-` prefix for cookies if supported, as it eliminates some common misconfigurations (can’t accidentally set Domain=somewhere insecure).",
    "Applicability": "This is an enhancement applicable to cookies in modern browsers. It’s a ‘should’ rather than ‘must’. Many secure apps don’t yet use __Host- and are still okay because they set Domain properly or not at all. If the application has no need for subdomain sharing of cookies, using __Host- is ideal. Mark N/A if the target environment or legacy support prevents use of this (older browsers might not understand it, but they just ignore unknown prefixes, so it’s usually fine). Generally, it’s applicable but not widely adopted – so absence isn’t a severe issue, presence is a plus.",
    "Sources": "https://owasp.org/ASVS/Session_Management#v344-cookie-name-prefixes, https://tools.ietf.org/html/draft-west-cookie-prefixes-05"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Cookies",
    "Item": "If other apps are on the same domain, ensure the cookie path attribute uses a specific path",
    "Description": "If the application shares a parent domain with other applications (e.g., app1.company.com and app2.company.com both set cookies for *.company.com, or multiple apps on the same domain/path), verify that the session cookie’s **Path** attribute is scoped narrowly (often Path=/ for host-scoped cookies, but in this context it suggests using a specific subpath if apps run under different paths on same domain). The idea is to prevent cookies from one app being sent to another unintentionally, which could pose security risks or cookie overwrites. For instance, if two apps on `example.com` use a cookie name `SESSIONID`, without path restrictions they might collide or be sent to each other’s endpoints. Setting Path properly (or using host-only cookies with no Domain set) isolates session cookies to the intended app.",
    "Tools": "- **Cookie Attributes**: Inspect the session cookie for a Path attribute. By default, many frameworks set Path=/, which means the cookie is sent to any URL on the same host. If multiple distinct apps share the host but perhaps reside under different base paths (like `/app1` vs `/app2` on the same domain), then ideally each app’s cookies should have Path=/app1 and /app2 respectively. If the apps are on different subdomains, the Domain attribute would be the differentiator instead. Essentially, verify cookies aren’t overly broad in scope beyond what’s needed.\n- **Cross-app Access Test**: If you have two apps on the same domain and you authenticate in one, see if that session cookie is sent when you browse to the other app. Use the browser dev tools to monitor requests. If it is sent and the names collide, one app might accidentally accept it or override it. If that’s observed, it’s misconfigured. If path is used correctly, the cookie shouldn’t go to the other app’s path.\n- **Review Configuration**: Check how cookies are set in server configs or code. If multiple apps on a domain, they should either use different subdomains (preferred) or at least distinct cookie names and path. If the Path is not set and defaults to /, consider if that’s okay. If each app is on its own subdomain (which is common), then this might not matter (each app’s cookie is host-scoped by virtue of no Domain attribute set beyond itself). So interpret accordingly: this mainly matters if apps share the same parent domain.\n- **Domain Attribute**: Similarly, if Domain=company.com is set (to allow subdomain sharing) but isn’t necessary, that’s broader than needed. Ideally Domain is not set (cookie defaults to host-only). Highlight if Domain is unnecessarily broad, because that also causes cookies to go to sibling subdomains.",
    "Links": "- **OWASP ASVS 3.4.5** – Talks about scoping cookies to specific path or host to avoid overlap between applications.\n- **CWE-16 Configuration** – Although not a specific CWE, misconfigured cookie scope is a configuration weakness. It can lead to sessions sent to wrong endpoints. OWASP cheatsheets suggest least scope for cookies: do not use wide Domain unless needed, and use Path if multiple apps on one domain.\n- **Mozilla Dev – Cookie Scope**: Documentation notes that Domain and Path define cookie scope. If multiple apps share domain, Path should be used to isolate them when possible.",
    "Applicability": "Applies when multiple applications or contexts share a common domain. If this web app is the only one on its domain, Path=/ is fine and likely needed. So if only one app on domain, mark N/A or note that it’s not a concern. If multiple apps on same domain or subdirectories, then this check is important. Also relevant for large organizations that might set enterprise-wide auth cookies on parent domain; they must be careful not to clash. So determine context and apply accordingly.",
    "Sources": "https://owasp.org/ASVS/Session_Management#v345-cookie-path-scope, https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#cookie_scope"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Token-based",
    "Item": "Application should allow users to revoke oauth tokens",
    "Description": "If the application uses OAuth tokens (or similar API access tokens, refresh tokens, etc.), verify there’s a mechanism for users to revoke those tokens. For example, if a user authorized a third-party app via OAuth, they should be able to later revoke that app’s access (invalidate the token). Similarly, if the app issues long-lived API tokens or mobile tokens, the user should have a way to invalidate them (through a “logout all devices” or a dedicated token management UI). This ensures users can cut off access if a token is compromised or no longer needed, adhering to least privilege and giving control. Without this, a stolen OAuth token might remain valid until expiry with no way for the user to force-invalidate it.",
    "Tools": "- **UI Inspection**: Look for a security or account settings page where connected applications or active tokens are listed. For instance, “Apps with access to your account” or an API token management screen. If present, attempt to revoke a token and ensure it actually invalidates access. For example, after revocation, using that token for API calls should fail (you can test if you have the token saved or via the third-party app scenario if possible).\n- **API Calls**: If no UI, see if there’s an API endpoint for token revocation (common in OAuth 2.0 spec – /revoke endpoint). Some apps implement the OAuth token but forget a revoke feature. Using the token’s client credentials, try calling such endpoint if documented.\n- **Check Documentation**: Application docs or help might mention how to de-authorize third-party access or manage tokens. If it explicitly says “Currently, you cannot revoke tokens, they expire in 30 days” – that’s a finding (lack of user control). If it says you can, follow those steps.\n- **Token Lifetime**: If revocation isn’t available, what is the token lifetime? If tokens are short-lived (minutes/hours) and cannot be refreshed indefinitely, the risk is lower. But if long-lived (days/months) without revocation, that’s a bigger issue. Document what you find.",
    "Links": "- **OWASP ASVS 4.0.4** – For OAuth and token-based schemes, ASVS suggests that users should have an option to revoke tokens or that sessions can be invalidated (similar principle).\n- **OAuth 2.0 RFC 7009** – Defines a standard token revocation endpoint. Proper OAuth implementations should provide this. If the app uses OAuth, supporting RFC7009 or equivalent user-facing revocation is best practice.\n- **OWASP API Security Top 10 (2019) – A5 Broken Function Level Authorization** – Not directly about revocation, but controlling tokens often falls under API security responsibilities. Also, not having token revocation doesn’t directly map to a Top10 category except maybe improper asset management, but it is a recommended security feature.",
    "Applicability": "Relevant to apps using OAuth 2.0 (social logins, authorization to third parties) or any long-lived tokens for API/mobile usage. If the app only uses traditional web sessions and no API tokens, this is N/A. If it uses short-lived tokens with no refresh, revocation is less of an issue (they die quickly anyway). But if using refresh tokens or enduring access tokens, then users (or at least administrators) should be able to revoke. So, check context: for pure OAuth flows or where user can link accounts, definitely applicable.",
    "Sources": "https://datatracker.ietf.org/doc/html/rfc7009, https://oauth.net/2/token-revocation/"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Token-based",
    "Item": "Application should use session tokens rather than static API keys/secrets",
    "Description": "Ensure that for user interactions, the application uses expirable session tokens (or one-time tokens) instead of long-lived static credentials in client-side code or storage. Static API keys or secrets (that never or rarely change) embedded in a client or issued to users can be problematic because if they leak, they grant access until manually revoked. A more secure design is to use session tokens that expire or rotate, reducing the window of compromise. Essentially, this item checks that the app isn’t relying on a hard-coded or user-specific static token for authentication for normal sessions when a session mechanism would suffice. This is a bit conceptual – likely targeting SPA/mobile use of long-term tokens vs. proper session handling.",
    "Tools": "- **Review Auth Mechanism**: Identify how the app authenticates API calls. If it uses an Authorization header with a Bearer token that looks like a JWT or session token that expires, that’s good. If instead it requires an API key that the user copies once and uses forever, note that. Static API keys (like ones you manually put in an app) are okay for certain use-cases (third-party integrations) but not ideal for user login sessions.\n- **Code Inspection**: Check if in the mobile app or JavaScript there are any static secrets (like an API key) included. That’s a bad practice as it can be extracted. A proper approach would be: user logs in, gets a token, uses that. If the app only uses a static API key for all users or per user but never changes, that’s weaker.\n- **Token Rotation**: If the application uses refresh tokens or some rotation mechanism, that’s in line with using session tokens rather than static ones. Confirm that either cookies or short-term tokens are in play. If you see something like a “secret” that doesn’t expire (unless user manually regenerates it), question if that could be replaced with a shorter-lived session token.\n- **Ask Why**: Sometimes devs choose static tokens for simplicity (e.g., basic auth with API key in mobile app). Engage or reason if that design is necessary. Usually, the recommendation is to use OAuth2 or some session endpoint instead of embedding keys. If static keys are used, ensure at least they can be rotated/revoked by user (ties to previous item).",
    "Links": "- **OWASP MASVS (Mobile) 5.3** – Advises against embedding API keys or secrets in the app code, instead use proper token-based auth. While mobile-focused, the principle is the same: no long-lived hard-coded secrets.\n- **OWASP API Security Top 10 – A2 Broken User Auth**: One example of broken auth is using static tokens improperly, where an attacker who finds one can indefinitely act as that user. Proper session tokens mitigate this by expiring.\n- **NIST 800-63B** – Suggests session-based authentication for users and discourages use of long-term shared secrets for sessions. Instead, use things that timeout or can be managed dynamically (it's implied in session management best practices).",
    "Applicability": "This is relevant if the app under test is using some form of API key or static token for user auth. Many web apps won’t (they use sessions/cookies). But mobile apps or SPAs might. If not applicable (no static secrets in use), mark N/A. It’s a design recommendation: if you find static API keys especially in client-side, it’s a risk. So apply when found. If the app has an “API key” feature for users (like to integrate their account with something), ensure those are not used in lieu of proper sessions for normal usage.",
    "Sources": "https://mobile-security.gitbook.io/masvs/0x05j-testing-authentication-and-session-management#checklist-auth, https://owasp.org/www-project-api-security/"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Token-based",
    "Item": "Stateless session tokens should use signatures or encryption to protect against tampering or replay",
    "Description": "If the application uses stateless session tokens (like JWTs or other self-contained tokens) rather than server-stored sessions, then those tokens must be integrity-protected (typically via a digital signature or HMAC) and possibly encrypted if they carry sensitive info. This is to prevent attackers from modifying the token (tampering) or reusing old tokens (replay) without detection. A signed JWT, for example, cannot be altered without invalidating the signature, and if it has a timestamp/expiration and possibly a nonce, it can mitigate replay. We need to verify that any stateless token is correctly implemented: signed with a strong secret, not using “alg:none” or an insecure method, and including claims like exp (expiration) to limit replay window.",
    "Tools": "- **Token Inspection**: If JWTs are used, decode a token (header and payload) and verify the algorithm (e.g., `alg` isn’t `none`, and is a strong algorithm like HS256, RS256, ES256, etc.). Check the payload for an `exp` (expiration time) claim, and maybe `iat` (issued at) or `nbf` (not before) claims. Absence of exp means the token could be replayed indefinitely until server secret changes or some other action. Also check if the token ID (`jti`) or other anti-replay mechanisms are present if needed (not always present, but a short expiration can serve the purpose too).\n- **Tampering Test**: As a light test, modify the payload of the JWT (like change your user ID or role in the token) and re-encode with the original header and signature to see if the server accepts it. It should reject it because the signature won’t match. If it accepts a tampered token, that indicates no proper signing (or a serious flaw like not validating signature or using alg=none vulnerability):contentReference[oaicite:97]{index=97}.\n- **Signature Verification**: Using tools like **jwt.io** or libraries, attempt to verify the token’s signature with a guessed key or known public key if using asymmetric. If you can guess the key (like it's something weak), that's an issue. Or if the token’s header says `alg: none`, it means it’s not signed at all – critical issue. Also, check for known flaws like `alg: HS256` with a public key confusion (if the server wrongly accepts a token signed with its public key as HMAC key, etc., which was a known JWT exploit scenario). This is complex, but basically ensure proper JWT library usage.\n- **Replay Consideration**: If tokens have long expiration or no jti, consider if an intercepted token could be replayed. Many systems just rely on short lifespans and TLS to prevent replay. That can be acceptable. But note if any additional replay defenses are used (some use jti with a server blacklist of used tokens, but that reintroduces state). Typically, short expiration and one-time refresh usage is how stateless tokens avoid replay issues.",
    "Links": "- **OWASP ASVS 3.1.5 & 3.1.6** – These cover that tokens or session IDs should be protected against prediction/tampering. For JWT, ASVS level 2/3 has requirements to use strong algorithms and to include exp claims, etc.\n- **OWASP JWT Cheat Sheet** – Emphasizes always signing tokens (never use alg=none), using strong secrets for HMAC or proper key management for RSA, and including an expiration to limit token lifetime. It also mentions considering encryption (JWE) if the token has sensitive data, though signing is typically the minimum requirement.\n- **CWE-345** – “Insufficient Verification of Data Authenticity” can apply if tokens aren’t signed/integrity-checked. Also **CWE-319** maybe for lack of encryption if needed. Essentially, these cover not ensuring data (token) is from a trusted source unaltered.",
    "Applicability": "This is specific to stateless token systems. If the app uses server-side sessions (session IDs stored in a DB or memory and just a random ref), then token tampering isn’t relevant (the ID is random; one can’t meaningfully tamper it except guess, which is covered by entropy checks). So mark N/A for traditional session-id cookies. But if using JWT or similar self-contained tokens for auth, this check is crucial. Also for any client-to-client tokens like password reset links or one-time tokens, ensure they’re unguessable and maybe signed. But main focus: JWT/OAuth access tokens.",
    "Sources": "https://owasp.org/www-project-cheat-sheets/cheatsheets/JSON_Web_Token_Cheat_Sheet_for_Java.html, https://datatracker.ietf.org/doc/html/rfc7519"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "JWT",
    "Item": "JWT issues (weak key, alg:None, sensitive information etc)",
    "Description": "Assess common JWT (JSON Web Token) vulnerabilities: ensure that the JWT is signed with a strong key and algorithm (no `alg: none` trick, no using HS256 with a trivial secret or with what should be an RS256 public key), that it doesn’t embed sensitive data in plaintext (like passwords or personal info in the token’s payload), and that token handling is secure (proper validation of signature and claims on the server). JWT-specific issues include algorithm confusion, missing signature verification, weak signing keys, overly long expiration, or including things in the token that give away info or should not be client-visible.",
    "Tools": "- **Decode and Inspect**: Use jwt.io or another JWT library to decode the token. Look at header: ensure `alg` is not “none” (which means no signing). If `alg` is e.g. HS256 or RS256, that’s okay if keys are properly managed. Check payload: is there any PII or sensitive data like user’s roles (which is okay if validated, but if the client can see it, consider if that’s acceptable) or worse, something like a password hash or credit card info (should never be in token). Also see if `exp` claim exists and is reasonable (not like exp in year 2099). If `exp` is missing, token might never expire – issue.\n- **Signature Verification**: Try to verify the token’s signature. If HS256, you’d need the secret – we might not have it, but you can attempt a brute force if it’s weak (not usually feasible unless it’s known small phrase). If RS256, you’d need the public key. Sometimes the app provides its public key via an endpoint or JWKS (JSON Web Key Set) if it’s a proper OIDC server. If available, use it to verify signature. This ensures the token is indeed properly signed by the server (and you could also then test changing something to see verification fails server-side as earlier). If “none” algorithm or if you can change alg to none and re-send token and it’s accepted, that’s a critical flaw (some libraries had this issue if misconfigured).\n- **Test Algorithm Confusion**: If the token uses RS256, see if the server mistakenly accepts it as HS256 with the public key as the secret (an old JWT attack). This is hard without access but you could craft a token header changing alg to HS256 and sign with the server’s public key as the key. If the server doesn’t properly enforce algorithm, it might accept. This is a niche but known vulnerability in some implementations.\n- **Check Key Management**: If possible, find out how the JWT signing key is managed. If it’s a hard-coded string like “secret”, that’s weak (there was an infamous incident where many JWTs used “secret” as key). We usually can’t see that externally unless brute force. But if trivial, you might break it by trying common words. If you can sign a token with “secret” and it’s accepted, the key is dangerously weak/default.\n- **Claim Validation**: See if the server validates claims like `aud` (audience), `iss` (issuer). If you change those in the token (keeping signature valid), does the server care? If not, maybe a minor issue. If you can change `iat` or remove `exp` and it still works, the server might not be validating expiration. Try using an expired token (modify exp to a past time but sign with original key) and see if it’s rejected; it should be.",
    "Links": "- **OWASP JWT Cheat Sheet** – Summarizes common JWT issues: use strong keys, always verify signature and claims, disallow `alg: none`, be cautious with token contents:contentReference[oaicite:103]{index=103}.\n- **Auth0 JWT Attacks Blog** – Details the alg:none and RSA/HS256 confusion attacks, and importance of proper validation. It's a well-known reference for what can go wrong with JWT if implemented incorrectly.\n- **CWE-347** – “Improper Verification of Cryptographic Signature” – applicable to accepting JWT without verifying signature or using `none`. Also **CWE-565** might apply for “Reliance on Cookies without Validation” if they just trust the JWT wholly. Essentially, these indicate the failures if JWT is not handled right.",
    "Applicability": "Only relevant if the app uses JWTs for session or auth. If not, skip. Many modern SPAs and mobile backends use JWT. Traditional web apps with cookies might not. Whenever JWT is in play, these checks are high priority because JWT flaws can lead to auth bypass or data exposure. So apply to APIs with Bearer tokens, OIDC tokens, etc.",
    "Sources": "https://owasp.org/www-project-cheat-sheets/cheatsheets/JSON_Web_Token_Cheat_Sheet_for_Java.html#vulnerabilities, https://auth0.com/blog/critical-vulnerabilities-in-json-web-token-libraries/"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Reauthentication from Federation",
    "Item": "Relaying parties should specify maximum authentication time to Credential Service Providers + should reauth user if",
    "Description": "This refers to federated login (like SSO/OAuth/OIDC). When our app (relying party, RP) delegates auth to an Identity Provider (credential service provider, CSP), the RP should indicate to the IdP how fresh the authentication needs to be. For example, using OIDC parameter `max_age` to say “if the user last authenticated more than N minutes ago, force a re-login”. Also, if the IdP tells the RP that the last auth was long ago, the RP should enforce reauthentication for sensitive actions. Essentially, ensure that federated logins aren’t blindly accepted if stale. The RP should either request reauth after a timeout or have the IdP prompt the user again after a certain time. This prevents scenarios where a user stays logged in at the IdP for days and automatically logs into the RP without ever re-verifying credentials, which might be too lax for high-security apps.",
    "Tools": "- **SSO Flow Analysis**: If the app uses SAML or OIDC for login, check the authentication requests. In OIDC, look for `max_age` parameter in the auth request the RP sends. If it's absent, that means by default the IdP could reuse a login indefinitely (depending on IdP config). If present, note the value (e.g., `max_age=3600` for one hour, meaning if last login at IdP >1h, user will be prompted again). In SAML, look for conditions like `ForceAuthn=true` or similar on the AuthnRequest. If the app is high-security, not using these might be a design issue.\n- **Test Reauthentication**: If possible, log into the app via SSO, then remain idle until what you think the reauth policy should be (or simulate by fiddling with IdP session). Then try accessing a sensitive function. Does the app or IdP prompt for login again? If not, and if a long time has passed, maybe the RP isn’t enforcing any max age. For example, if you have an IdP session from yesterday and you log into the RP today and it doesn’t ask you to log in again at IdP, and the app itself doesn’t ask for a password, that might violate a stricter security requirement (depending on context). For test, sometimes you can include `max_age=0` manually to see if IdP forces login.\n- **Claims Inspection**: In OIDC, the ID Token often has an `auth_time` claim (time the user last authenticated at IdP). Check if the RP is using it. Hard to see externally, but if you decode the ID token, you'll see `auth_time`. If the app never asks you to re-login even though `auth_time` is far in the past, they likely aren’t using it to enforce fresh login for sensitive actions.\n- **Policy Check**: If this is a regulated or sensitive app, there might be a policy like “users must re-authenticate after 12 hours even if SSO”. Check documentation or ask about reauth requirements. If the app doesn’t align (no max_age set, never reauths), that’s a point to raise.",
    "Links": "- **OWASP ASVS 4.2.4** – Talks about reauthentication requirements for sensitive transactions and suggests that federated setups should respect those (for instance, not letting an IdP’s long-lived session bypass an RP’s need for a fresh login).\n- **NIST SP 800-63B Section 7.2.1** – Federation guidelines mention that RPs can request a fresh assertion or set a maximum acceptable authentication age. NIST suggests that high assurance sessions have limitations on reuse of old logins.\n- **SAML/OIDC Best Practices** – Both protocols allow for forcing a new login. E.g., SAML’s `<AuthnRequest ForceAuthn=\"true\"/>` ensures IdP asks user to log in again. OIDC’s `max_age` and `prompt=login` do similarly. Best practice in security-critical apps is to use these for actions or periodically.",
    "Applicability": "Only applicable for applications using federated identity (SAML, OAuth2/OIDC, etc.). If not using that, mark N/A. Within that, it’s especially relevant if the IdP sessions are long and the app is sensitive. If the app is low-risk and users value seamless SSO more, they might intentionally not set this – but from a strict security view, lack of any reauth on federation can be noted. It’s more a design choice but ASVS seems to encourage it. So, use judgement based on app sensitivity.",
    "Sources": "https://openid.net/specs/openid-connect-core-1_0.html#AuthRequest (see max_age), https://docs.oasis-open.org/security/saml/v2.0/saml-core-2.0-os.pdf (ForceAuthn in SAML AuthnRequest)"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Reauthentication from Federation",
    "Item": "Credential Service Providers inform RPs of last auth event ",
    "Description": "This item complements the previous one: The Identity Provider (Credential Service Provider, CSP) should communicate to the Relying Party (RP) the time of the user’s last authentication (often via an `auth_time` claim in OIDC or SessionIndex in SAML). The RP should use that information to decide if the current session is too old and require reauth. Essentially, ensure that in a federated login, the IdP is providing a timestamp of when it last verified the user (not just when the token was issued), and that the RP is aware of it. This helps the RP enforce its policies (like requiring re-login every X hours). Without it, the RP can’t know if the user has recently authenticated or if the IdP just silently used an old session. So, check that such info is present and (ideally) used.",
    "Tools": "- **Token/Assertion Inspection**: For OIDC, decode the ID Token and look for the `auth_time` field. For SAML, in the SAML assertion, look at the `<AuthnStatement AuthnInstant=\"...\">` which gives the timestamp of authentication. Verify these exist. If not present, the IdP may not be configured to include it (OIDC requires `max_age` request or specific config to always include auth_time if necessary). The presence of `auth_time` is good; absence might indicate the RP can’t enforce age rules (unless it always requires fresh login via prompt=login or something when needed).\n- **RP Application Behavior**: Hard to directly test if RP uses auth_time, but if you have a scenario: log in via SSO, note the auth_time from token. If you reuse the SSO after a long time, does the application ask you to login again (implying it considered auth_time too old)? Possibly try to manipulate a scenario: If you can craft an ID token with a very old auth_time (not straightforward without signing keys, so likely no). Instead, rely on design knowledge: ask developers or see documentation if the RP has a setting like “maximum IdP session reuse duration”. If the IdP is under same company, check if they include auth_time by default.\n- **NIST Compliance Inquiry**: If this is all derived from NIST guidelines, maybe the org has a statement like “Our IdP includes auth_time in tokens, and RPs enforce reauth after 12h”. If yes, verify if it’s happening. If tokens clearly have auth_time and the RP had the earlier logic, then likely they consider it.\n- **Logging**: As a stretch, if you have access to logs (or maybe the JWT is stored in local storage or cookie), see if the application logs or records the auth_time anywhere. Unlikely though; usually it's internal.",
    "Links": "- **NIST SP 800-63C** (Federation) – Recommends that IdPs provide the RP with the time of authentication and level of assurance so the RP can make informed decisions. `auth_time` in OIDC is directly from these guidelines for federation.\n- **OWASP ASVS** – Touched on previous item: essentially if the RP sets max_age, the IdP must supply auth_time to comply. ASVS expects that interplay as part of secure session mgmt in federated scenario.\n- **OIDC Core Spec** – The `auth_time` claim definition: if an RP requests it (or certain conditions), the IdP will include it. The RP can then use it to ensure the user authenticated recently enough.",
    "Applicability": "Again, only for federated login setups. If applicable, it's somewhat an implementation detail between IdP and RP, but it's a necessary piece for high security RPs. If the app is standalone or uses its own login, N/A. If using third-party IdP (like Google login for a low-risk app), usually Google will include auth_time by spec but the app may not care. It’s more critical for enterprise setups with compliance requirements. So apply accordingly.",
    "Sources": "https://openid.net/specs/openid-connect-core-1_0.html#IDToken (auth_time claim), https://pages.nist.gov/800-63-3/sp800-63c.html#assertion"
  },
  {
    "Category": "Session Management (v3)",
    "Sub Category": "Defenses Against Session Management Exploits",
    "Item": "App ensures a full valid login before allowing sensitive transactions/account modifications (e.g. pre-MFA changes)",
    "Description": "This means the application should require that the user has fully authenticated (and possibly re-authenticated) before performing highly sensitive actions, especially those that could be attempted by a partially authenticated or session-hijacked user. For example, some apps may have flows where part of the session is authenticated via a token link (like email verification) but not fully logged in – the app should ensure the user actually logs in or provides credentials before critical operations. Another angle: if the app uses MFA (multi-factor auth), ensure that the second factor was completed for sensitive actions (like changing password, editing account settings). Essentially, double-check that no sensitive function can be executed on a session that hasn’t gone through complete auth checks (username+password and MFA if applicable). This defends against session fixation or CSRF in flows before login is finalized.",
    "Tools": "- **Workflow Analysis**: Identify if there are any multi-step auth processes. E.g., account recovery, email verification flows, or MFA enrollment steps. During those flows, see if any sensitive action can be done in parallel or by abusing the partially authenticated session. For instance, if you click a password reset link (which gives some session state often), does that session let you directly access account settings without logging in? It shouldn’t – you should only be able to reset password, nothing else.\n- **MFA Checks**: If MFA is optional or only for certain actions, test performing a sensitive action without completing MFA. E.g., log in with just password (if app allows skipping MFA or it’s not enforced for all) and then try to change a security setting. Or if MFA is supposed to be enforced for that, see if it's possible to circumvent (like directly call the endpoint with the session that didn’t do MFA). The app should respond with “additional auth needed” if properly implemented.\n- **Session States**: If the application has a concept of “partially logged in” (maybe after username+password but before OTP), ensure that state is tracked and sensitive operations check for “fully authenticated” flag. One can sometimes find clues in session or tokens (a claim like `amr` for authentication methods used). If your session cookie changes or gains attributes after MFA, that’s good. If not, and you can skip MFA for some action, that’s a hole.\n- **Testing CSRF/Session Fixation together**: In some forgot-password flows, you can do session fixation: e.g., open a session, send password reset link to victim, if victim clicks, they might be logged in under a session you control but maybe not fully recognized as such by the app in some corner case. The app should require a fresh login after such flow or at least treat that session specially. Try odd sequences like using a token link, then browsing site as if logged in. If you find any weird access, that’s an issue.",
    "Links": "- **OWASP ASVS 2.2.3 & 2.2.5** – These talk about requiring re-authentication or step-up auth for sensitive actions (like changing password or viewing sensitive data). It implies that just being “logged in” isn’t enough for certain actions – you might need to provide credentials again or have done MFA. The app should enforce full auth.\n- **NIST 800-63B** – Recommends re-verification of user for sensitive transactions (e.g., prompt for password again or have recently logged-in check). It also says if a session hasn’t done MFA and the action requires it, the user must do MFA first.\n- **OWASP Top 10 – A2 Broken Auth**: A partial session that can do things as if fully auth’d would be considered a broken auth scenario. Ensuring full valid login (including all factors) before critical changes is a measure to counter that.",
    "Applicability": "Applies to applications with multi-step auth (MFA, password resets, email verification links) or particularly sensitive features (changing email, password, downloading personal data, etc.). If the app is basic and once you’re logged in with password you have no second factor or partial states, then main thing is maybe requiring password again for critical actions. That’s common in financial or high-security apps (e.g., “enter your password to confirm this transfer”). If the app has none of those flows or second factors, this may be less applicable. Still, any sensitive function might ideally have a reauth; check if that’s expected. Otherwise, if not in design, not applicable as a “lack” unless risk demands it.",
    "Sources": "https://owasp.org/ASVS/Authentication_Verification_Requirements#v223-mfa-before-sensitive-operations, https://pages.nist.gov/800-63-3/sp800-63b.html#reauthentication"
  }
]
